{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "from transform import get_X_y\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow modules. tensorflow was run on a docker container\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "# tf.config.threading.set_intra_op_parallelism_threads(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import sklearn modules\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbit = pd.read_csv('../data/samples_2_bodies_3_dim_1_m_com.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sim_id</th>\n",
       "      <th>m_1</th>\n",
       "      <th>m_2</th>\n",
       "      <th>rx_1_0</th>\n",
       "      <th>ry_1_0</th>\n",
       "      <th>rz_1_0</th>\n",
       "      <th>rx_2_0</th>\n",
       "      <th>ry_2_0</th>\n",
       "      <th>rz_2_0</th>\n",
       "      <th>vx_1_0</th>\n",
       "      <th>...</th>\n",
       "      <th>rz_1_1000</th>\n",
       "      <th>rx_2_1000</th>\n",
       "      <th>ry_2_1000</th>\n",
       "      <th>rz_2_1000</th>\n",
       "      <th>vx_1_1000</th>\n",
       "      <th>vy_1_1000</th>\n",
       "      <th>vz_1_1000</th>\n",
       "      <th>vx_2_1000</th>\n",
       "      <th>vy_2_1000</th>\n",
       "      <th>vz_2_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.072812</td>\n",
       "      <td>0.339681</td>\n",
       "      <td>0.234807</td>\n",
       "      <td>-0.072812</td>\n",
       "      <td>-0.339681</td>\n",
       "      <td>-0.234807</td>\n",
       "      <td>0.032668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245414</td>\n",
       "      <td>-0.062839</td>\n",
       "      <td>-0.156803</td>\n",
       "      <td>-0.245414</td>\n",
       "      <td>-0.104210</td>\n",
       "      <td>-0.721673</td>\n",
       "      <td>-0.262195</td>\n",
       "      <td>0.104210</td>\n",
       "      <td>0.721673</td>\n",
       "      <td>0.262195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.054407</td>\n",
       "      <td>0.105241</td>\n",
       "      <td>0.222055</td>\n",
       "      <td>-0.054407</td>\n",
       "      <td>-0.105241</td>\n",
       "      <td>-0.222055</td>\n",
       "      <td>-0.151459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>-0.017101</td>\n",
       "      <td>-0.250963</td>\n",
       "      <td>-0.001457</td>\n",
       "      <td>0.167632</td>\n",
       "      <td>0.763737</td>\n",
       "      <td>0.546329</td>\n",
       "      <td>-0.167632</td>\n",
       "      <td>-0.763737</td>\n",
       "      <td>-0.546329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015466</td>\n",
       "      <td>-0.034834</td>\n",
       "      <td>0.083430</td>\n",
       "      <td>-0.015466</td>\n",
       "      <td>0.034834</td>\n",
       "      <td>-0.083430</td>\n",
       "      <td>-0.452646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080874</td>\n",
       "      <td>-0.039404</td>\n",
       "      <td>-0.331130</td>\n",
       "      <td>-0.080874</td>\n",
       "      <td>0.128510</td>\n",
       "      <td>0.343728</td>\n",
       "      <td>0.494653</td>\n",
       "      <td>-0.128510</td>\n",
       "      <td>-0.343728</td>\n",
       "      <td>-0.494653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.060140</td>\n",
       "      <td>0.364899</td>\n",
       "      <td>0.167492</td>\n",
       "      <td>-0.060140</td>\n",
       "      <td>-0.364899</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>0.083064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261195</td>\n",
       "      <td>-0.074577</td>\n",
       "      <td>-0.281935</td>\n",
       "      <td>-0.261195</td>\n",
       "      <td>-0.013481</td>\n",
       "      <td>-0.439943</td>\n",
       "      <td>0.074785</td>\n",
       "      <td>0.013481</td>\n",
       "      <td>0.439943</td>\n",
       "      <td>-0.074785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017181</td>\n",
       "      <td>0.251330</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>-0.017181</td>\n",
       "      <td>-0.251330</td>\n",
       "      <td>-0.001720</td>\n",
       "      <td>0.167503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181902</td>\n",
       "      <td>-0.063202</td>\n",
       "      <td>-0.364724</td>\n",
       "      <td>-0.181902</td>\n",
       "      <td>0.074315</td>\n",
       "      <td>-0.030131</td>\n",
       "      <td>0.357845</td>\n",
       "      <td>-0.074315</td>\n",
       "      <td>0.030131</td>\n",
       "      <td>-0.357845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.056611</td>\n",
       "      <td>0.192364</td>\n",
       "      <td>-0.247187</td>\n",
       "      <td>0.056611</td>\n",
       "      <td>-0.192364</td>\n",
       "      <td>0.247187</td>\n",
       "      <td>-0.214536</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125396</td>\n",
       "      <td>0.077384</td>\n",
       "      <td>-0.004295</td>\n",
       "      <td>0.125396</td>\n",
       "      <td>0.130841</td>\n",
       "      <td>-1.165302</td>\n",
       "      <td>1.163385</td>\n",
       "      <td>-0.130841</td>\n",
       "      <td>1.165302</td>\n",
       "      <td>-1.163385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.062381</td>\n",
       "      <td>-0.046865</td>\n",
       "      <td>-0.059740</td>\n",
       "      <td>0.062381</td>\n",
       "      <td>0.046865</td>\n",
       "      <td>0.059740</td>\n",
       "      <td>0.604474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126458</td>\n",
       "      <td>-0.132333</td>\n",
       "      <td>-0.099748</td>\n",
       "      <td>-0.126458</td>\n",
       "      <td>0.632941</td>\n",
       "      <td>1.154271</td>\n",
       "      <td>0.048515</td>\n",
       "      <td>-0.632941</td>\n",
       "      <td>-1.154271</td>\n",
       "      <td>-0.048515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250455</td>\n",
       "      <td>0.441298</td>\n",
       "      <td>0.031888</td>\n",
       "      <td>-0.250455</td>\n",
       "      <td>-0.441298</td>\n",
       "      <td>-0.031888</td>\n",
       "      <td>0.071420</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021397</td>\n",
       "      <td>-0.256480</td>\n",
       "      <td>-0.517709</td>\n",
       "      <td>0.021397</td>\n",
       "      <td>-0.002030</td>\n",
       "      <td>0.345303</td>\n",
       "      <td>-0.286874</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>-0.345303</td>\n",
       "      <td>0.286874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.117538</td>\n",
       "      <td>0.560847</td>\n",
       "      <td>-0.275648</td>\n",
       "      <td>-0.117538</td>\n",
       "      <td>-0.560847</td>\n",
       "      <td>0.275648</td>\n",
       "      <td>-0.211689</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294678</td>\n",
       "      <td>-0.076410</td>\n",
       "      <td>-0.505170</td>\n",
       "      <td>0.294678</td>\n",
       "      <td>-0.231047</td>\n",
       "      <td>-0.354711</td>\n",
       "      <td>-0.072457</td>\n",
       "      <td>0.231047</td>\n",
       "      <td>0.354711</td>\n",
       "      <td>0.072457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.088238</td>\n",
       "      <td>0.522712</td>\n",
       "      <td>-0.290462</td>\n",
       "      <td>-0.088238</td>\n",
       "      <td>-0.522712</td>\n",
       "      <td>0.290462</td>\n",
       "      <td>-0.226049</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.300877</td>\n",
       "      <td>-0.044721</td>\n",
       "      <td>-0.451968</td>\n",
       "      <td>0.300877</td>\n",
       "      <td>-0.242035</td>\n",
       "      <td>-0.442254</td>\n",
       "      <td>-0.017841</td>\n",
       "      <td>0.242035</td>\n",
       "      <td>0.442254</td>\n",
       "      <td>0.017841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sim_id  m_1  m_2    rx_1_0    ry_1_0    rz_1_0    rx_2_0    ry_2_0  \\\n",
       "0          0.0  1.0  1.0  0.072812  0.339681  0.234807 -0.072812 -0.339681   \n",
       "1          0.0  1.0  1.0  0.054407  0.105241  0.222055 -0.054407 -0.105241   \n",
       "2          0.0  1.0  1.0  0.015466 -0.034834  0.083430 -0.015466  0.034834   \n",
       "3          0.0  1.0  1.0  0.060140  0.364899  0.167492 -0.060140 -0.364899   \n",
       "4          0.0  1.0  1.0  0.017181  0.251330  0.001720 -0.017181 -0.251330   \n",
       "...        ...  ...  ...       ...       ...       ...       ...       ...   \n",
       "199995  1999.0  1.0  1.0 -0.056611  0.192364 -0.247187  0.056611 -0.192364   \n",
       "199996  1999.0  1.0  1.0 -0.062381 -0.046865 -0.059740  0.062381  0.046865   \n",
       "199997  1999.0  1.0  1.0  0.250455  0.441298  0.031888 -0.250455 -0.441298   \n",
       "199998  1999.0  1.0  1.0  0.117538  0.560847 -0.275648 -0.117538 -0.560847   \n",
       "199999  1999.0  1.0  1.0  0.088238  0.522712 -0.290462 -0.088238 -0.522712   \n",
       "\n",
       "          rz_2_0    vx_1_0  ...  rz_1_1000  rx_2_1000  ry_2_1000  rz_2_1000  \\\n",
       "0      -0.234807  0.032668  ...   0.245414  -0.062839  -0.156803  -0.245414   \n",
       "1      -0.222055 -0.151459  ...   0.001457  -0.017101  -0.250963  -0.001457   \n",
       "2      -0.083430 -0.452646  ...   0.080874  -0.039404  -0.331130  -0.080874   \n",
       "3      -0.167492  0.083064  ...   0.261195  -0.074577  -0.281935  -0.261195   \n",
       "4      -0.001720  0.167503  ...   0.181902  -0.063202  -0.364724  -0.181902   \n",
       "...          ...       ...  ...        ...        ...        ...        ...   \n",
       "199995  0.247187 -0.214536  ...  -0.125396   0.077384  -0.004295   0.125396   \n",
       "199996  0.059740  0.604474  ...   0.126458  -0.132333  -0.099748  -0.126458   \n",
       "199997 -0.031888  0.071420  ...  -0.021397  -0.256480  -0.517709   0.021397   \n",
       "199998  0.275648 -0.211689  ...  -0.294678  -0.076410  -0.505170   0.294678   \n",
       "199999  0.290462 -0.226049  ...  -0.300877  -0.044721  -0.451968   0.300877   \n",
       "\n",
       "        vx_1_1000  vy_1_1000  vz_1_1000  vx_2_1000  vy_2_1000  vz_2_1000  \n",
       "0       -0.104210  -0.721673  -0.262195   0.104210   0.721673   0.262195  \n",
       "1        0.167632   0.763737   0.546329  -0.167632  -0.763737  -0.546329  \n",
       "2        0.128510   0.343728   0.494653  -0.128510  -0.343728  -0.494653  \n",
       "3       -0.013481  -0.439943   0.074785   0.013481   0.439943  -0.074785  \n",
       "4        0.074315  -0.030131   0.357845  -0.074315   0.030131  -0.357845  \n",
       "...           ...        ...        ...        ...        ...        ...  \n",
       "199995   0.130841  -1.165302   1.163385  -0.130841   1.165302  -1.163385  \n",
       "199996   0.632941   1.154271   0.048515  -0.632941  -1.154271  -0.048515  \n",
       "199997  -0.002030   0.345303  -0.286874   0.002030  -0.345303   0.286874  \n",
       "199998  -0.231047  -0.354711  -0.072457   0.231047   0.354711   0.072457  \n",
       "199999  -0.242035  -0.442254  -0.017841   0.242035   0.442254   0.017841  \n",
       "\n",
       "[200000 rows x 51 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 10\n",
    "X, y = get_X_y(orbit, steps, False, True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create and compile neural network\n",
    "\n",
    "n_samples, n_feats = X_train.shape\n",
    "_, n_outputs = y_train.shape\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "hidden_units = n_feats\n",
    "epochs=100\n",
    "learning_rate = 0.1\n",
    "decay_rate = learning_rate / epochs\n",
    "momentum = 0.8\n",
    "\n",
    "scale = 10\n",
    "\n",
    "\n",
    "hidden_layer = Dense(units=hidden_units,\n",
    "                input_dim=n_feats,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='relu')\n",
    "\n",
    "hidden_layer2 = Dense(units=hidden_units*scale,\n",
    "                input_dim=hidden_units,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='relu')\n",
    "\n",
    "hidden_layer3 = Dense(units=hidden_units*scale,\n",
    "                input_dim=hidden_units*scale,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='relu')\n",
    "\n",
    "hidden_layer4 = Dense(units=n_outputs,\n",
    "                input_dim=hidden_units*scale,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='relu')\n",
    "\n",
    "output_layer = Dense(units=n_outputs,\n",
    "                input_dim=hidden_units,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='linear')\n",
    "\n",
    "model.add(hidden_layer)\n",
    "# model.add(Dropout(rate=0.1))\n",
    "# model.add(hidden_layer2)\n",
    "# model.add(Dropout(rate=0.1))\n",
    "# model.add(hidden_layer3)\n",
    "# model.add(Dropout(rate=0.1))\n",
    "# model.add(hidden_layer3)\n",
    "# model.add(Dropout(rate=0.1))\n",
    "# model.add(hidden_layer3)\n",
    "# model.add(Dropout(rate=0.1))\n",
    "# model.add(hidden_layer3)\n",
    "# model.add(Dropout(rate=0.1))\n",
    "# model.add(hidden_layer3)\n",
    "# model.add(Dropout(rate=0.1))\n",
    "# model.add(hidden_layer3)\n",
    "# model.add(Dropout(rate=0.1))\n",
    "# model.add(hidden_layer4)\n",
    "# model.add(Dropout(rate=0.1))\n",
    "model.add(output_layer)\n",
    "model.add(Dropout(rate=0.1))\n",
    "\n",
    "sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "# sgd = SGD(lr=learning_rate)\n",
    "model.compile(loss='mean_squared_error', \n",
    "              optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120000 samples, validate on 30000 samples\n",
      "Epoch 1/100\n",
      "120000/120000 - 0s - loss: 5.9719 - val_loss: 0.7138\n",
      "Epoch 2/100\n",
      "120000/120000 - 0s - loss: 1.5788 - val_loss: 0.4609\n",
      "Epoch 3/100\n",
      "120000/120000 - 0s - loss: 1.5467 - val_loss: 0.4581\n",
      "Epoch 4/100\n",
      "120000/120000 - 0s - loss: 1.5249 - val_loss: 0.4591\n",
      "Epoch 5/100\n",
      "120000/120000 - 0s - loss: 1.4900 - val_loss: 0.4590\n",
      "Epoch 6/100\n",
      "120000/120000 - 0s - loss: 1.5189 - val_loss: 0.4590\n",
      "Epoch 7/100\n",
      "120000/120000 - 0s - loss: 1.5259 - val_loss: 0.4592\n",
      "Epoch 8/100\n",
      "120000/120000 - 0s - loss: 1.5154 - val_loss: 0.4590\n",
      "Epoch 9/100\n",
      "120000/120000 - 0s - loss: 1.5337 - val_loss: 0.4589\n",
      "Epoch 10/100\n",
      "120000/120000 - 0s - loss: 1.5507 - val_loss: 0.4593\n",
      "Epoch 11/100\n",
      "120000/120000 - 0s - loss: 1.5335 - val_loss: 0.4591\n",
      "Epoch 12/100\n",
      "120000/120000 - 0s - loss: 1.5177 - val_loss: 0.4590\n",
      "Epoch 13/100\n",
      "120000/120000 - 0s - loss: 1.5141 - val_loss: 0.4591\n",
      "Epoch 14/100\n",
      "120000/120000 - 0s - loss: 1.5308 - val_loss: 0.4589\n",
      "Epoch 15/100\n",
      "120000/120000 - 0s - loss: 1.5293 - val_loss: 0.4591\n",
      "Epoch 16/100\n",
      "120000/120000 - 0s - loss: 1.5212 - val_loss: 0.4591\n",
      "Epoch 17/100\n",
      "120000/120000 - 0s - loss: 1.5099 - val_loss: 0.4590\n",
      "Epoch 18/100\n",
      "120000/120000 - 0s - loss: 1.5123 - val_loss: 0.4589\n",
      "Epoch 19/100\n",
      "120000/120000 - 0s - loss: 1.5036 - val_loss: 0.4590\n",
      "Epoch 20/100\n",
      "120000/120000 - 0s - loss: 1.5145 - val_loss: 0.4590\n",
      "Epoch 21/100\n",
      "120000/120000 - 0s - loss: 1.5054 - val_loss: 0.4588\n",
      "Epoch 22/100\n",
      "120000/120000 - 0s - loss: 1.5317 - val_loss: 0.4590\n",
      "Epoch 23/100\n",
      "120000/120000 - 0s - loss: 1.5333 - val_loss: 0.4590\n",
      "Epoch 24/100\n",
      "120000/120000 - 0s - loss: 1.5100 - val_loss: 0.4592\n",
      "Epoch 25/100\n",
      "120000/120000 - 0s - loss: 1.5181 - val_loss: 0.4590\n",
      "Epoch 26/100\n",
      "120000/120000 - 0s - loss: 1.5107 - val_loss: 0.4590\n",
      "Epoch 27/100\n",
      "120000/120000 - 0s - loss: 1.5177 - val_loss: 0.4590\n",
      "Epoch 28/100\n",
      "120000/120000 - 0s - loss: 1.5388 - val_loss: 0.4591\n",
      "Epoch 29/100\n",
      "120000/120000 - 0s - loss: 1.5159 - val_loss: 0.4591\n",
      "Epoch 30/100\n",
      "120000/120000 - 0s - loss: 1.4911 - val_loss: 0.4590\n",
      "Epoch 31/100\n",
      "120000/120000 - 0s - loss: 1.5472 - val_loss: 0.4591\n",
      "Epoch 32/100\n",
      "120000/120000 - 0s - loss: 1.5360 - val_loss: 0.4589\n",
      "Epoch 33/100\n",
      "120000/120000 - 0s - loss: 1.4901 - val_loss: 0.4589\n",
      "Epoch 34/100\n",
      "120000/120000 - 0s - loss: 1.5206 - val_loss: 0.4589\n",
      "Epoch 35/100\n",
      "120000/120000 - 0s - loss: 1.5290 - val_loss: 0.4590\n",
      "Epoch 36/100\n",
      "120000/120000 - 0s - loss: 1.5347 - val_loss: 0.4591\n",
      "Epoch 37/100\n",
      "120000/120000 - 0s - loss: 1.5259 - val_loss: 0.4590\n",
      "Epoch 38/100\n",
      "120000/120000 - 0s - loss: 1.5275 - val_loss: 0.4591\n",
      "Epoch 39/100\n",
      "120000/120000 - 0s - loss: 1.5295 - val_loss: 0.4592\n",
      "Epoch 40/100\n",
      "120000/120000 - 0s - loss: 1.5448 - val_loss: 0.4590\n",
      "Epoch 41/100\n",
      "120000/120000 - 0s - loss: 1.4976 - val_loss: 0.4591\n",
      "Epoch 42/100\n",
      "120000/120000 - 0s - loss: 1.5305 - val_loss: 0.4591\n",
      "Epoch 43/100\n",
      "120000/120000 - 0s - loss: 1.5327 - val_loss: 0.4589\n",
      "Epoch 44/100\n",
      "120000/120000 - 0s - loss: 1.5130 - val_loss: 0.4590\n",
      "Epoch 45/100\n",
      "120000/120000 - 0s - loss: 1.5111 - val_loss: 0.4590\n",
      "Epoch 46/100\n",
      "120000/120000 - 0s - loss: 1.5298 - val_loss: 0.4591\n",
      "Epoch 47/100\n",
      "120000/120000 - 0s - loss: 1.5165 - val_loss: 0.4591\n",
      "Epoch 48/100\n",
      "120000/120000 - 0s - loss: 1.5359 - val_loss: 0.4590\n",
      "Epoch 49/100\n",
      "120000/120000 - 0s - loss: 1.5337 - val_loss: 0.4591\n",
      "Epoch 50/100\n",
      "120000/120000 - 0s - loss: 1.5490 - val_loss: 0.4590\n",
      "Epoch 51/100\n",
      "120000/120000 - 0s - loss: 1.5068 - val_loss: 0.4591\n",
      "Epoch 52/100\n",
      "120000/120000 - 0s - loss: 1.5550 - val_loss: 0.4592\n",
      "Epoch 53/100\n",
      "120000/120000 - 0s - loss: 1.5410 - val_loss: 0.4590\n",
      "Epoch 54/100\n",
      "120000/120000 - 0s - loss: 1.5127 - val_loss: 0.4591\n",
      "Epoch 55/100\n",
      "120000/120000 - 0s - loss: 1.5556 - val_loss: 0.4590\n",
      "Epoch 56/100\n",
      "120000/120000 - 0s - loss: 1.5822 - val_loss: 0.4590\n",
      "Epoch 57/100\n",
      "120000/120000 - 0s - loss: 1.5162 - val_loss: 0.4591\n",
      "Epoch 58/100\n",
      "120000/120000 - 0s - loss: 1.5253 - val_loss: 0.4590\n",
      "Epoch 59/100\n",
      "120000/120000 - 0s - loss: 1.5232 - val_loss: 0.4592\n",
      "Epoch 60/100\n",
      "120000/120000 - 0s - loss: 1.5045 - val_loss: 0.4590\n",
      "Epoch 61/100\n",
      "120000/120000 - 0s - loss: 1.5004 - val_loss: 0.4589\n",
      "Epoch 62/100\n",
      "120000/120000 - 0s - loss: 1.5120 - val_loss: 0.4591\n",
      "Epoch 63/100\n",
      "120000/120000 - 0s - loss: 1.5338 - val_loss: 0.4590\n",
      "Epoch 64/100\n",
      "120000/120000 - 0s - loss: 1.5387 - val_loss: 0.4591\n",
      "Epoch 65/100\n",
      "120000/120000 - 0s - loss: 1.5206 - val_loss: 0.4590\n",
      "Epoch 66/100\n",
      "120000/120000 - 0s - loss: 1.5090 - val_loss: 0.4590\n",
      "Epoch 67/100\n",
      "120000/120000 - 0s - loss: 1.5433 - val_loss: 0.4590\n",
      "Epoch 68/100\n",
      "120000/120000 - 0s - loss: 1.5017 - val_loss: 0.4591\n",
      "Epoch 69/100\n",
      "120000/120000 - 0s - loss: 1.5558 - val_loss: 0.4591\n",
      "Epoch 70/100\n",
      "120000/120000 - 0s - loss: 1.5083 - val_loss: 0.4591\n",
      "Epoch 71/100\n",
      "120000/120000 - 0s - loss: 1.5028 - val_loss: 0.4590\n",
      "Epoch 72/100\n",
      "120000/120000 - 0s - loss: 1.4961 - val_loss: 0.4589\n",
      "Epoch 73/100\n",
      "120000/120000 - 0s - loss: 1.4904 - val_loss: 0.4590\n",
      "Epoch 74/100\n",
      "120000/120000 - 0s - loss: 1.5125 - val_loss: 0.4591\n",
      "Epoch 75/100\n",
      "120000/120000 - 0s - loss: 1.4789 - val_loss: 0.4590\n",
      "Epoch 76/100\n",
      "120000/120000 - 0s - loss: 1.5057 - val_loss: 0.4590\n",
      "Epoch 77/100\n",
      "120000/120000 - 0s - loss: 1.5067 - val_loss: 0.4591\n",
      "Epoch 78/100\n",
      "120000/120000 - 0s - loss: 1.5039 - val_loss: 0.4591\n",
      "Epoch 79/100\n",
      "120000/120000 - 0s - loss: 1.5024 - val_loss: 0.4590\n",
      "Epoch 80/100\n",
      "120000/120000 - 0s - loss: 1.5353 - val_loss: 0.4589\n",
      "Epoch 81/100\n",
      "120000/120000 - 0s - loss: 1.5150 - val_loss: 0.4591\n",
      "Epoch 82/100\n",
      "120000/120000 - 0s - loss: 1.5298 - val_loss: 0.4591\n",
      "Epoch 83/100\n",
      "120000/120000 - 0s - loss: 1.5398 - val_loss: 0.4589\n",
      "Epoch 84/100\n",
      "120000/120000 - 0s - loss: 1.5260 - val_loss: 0.4591\n",
      "Epoch 85/100\n",
      "120000/120000 - 0s - loss: 1.5060 - val_loss: 0.4590\n",
      "Epoch 86/100\n",
      "120000/120000 - 0s - loss: 1.5178 - val_loss: 0.4590\n",
      "Epoch 87/100\n",
      "120000/120000 - 0s - loss: 1.4968 - val_loss: 0.4590\n",
      "Epoch 88/100\n",
      "120000/120000 - 0s - loss: 1.5398 - val_loss: 0.4590\n",
      "Epoch 89/100\n",
      "120000/120000 - 0s - loss: 1.5306 - val_loss: 0.4590\n",
      "Epoch 90/100\n",
      "120000/120000 - 0s - loss: 1.5341 - val_loss: 0.4590\n",
      "Epoch 91/100\n",
      "120000/120000 - 0s - loss: 1.5305 - val_loss: 0.4590\n",
      "Epoch 92/100\n",
      "120000/120000 - 0s - loss: 1.5045 - val_loss: 0.4591\n",
      "Epoch 93/100\n",
      "120000/120000 - 0s - loss: 1.5495 - val_loss: 0.4590\n",
      "Epoch 94/100\n",
      "120000/120000 - 0s - loss: 1.5118 - val_loss: 0.4591\n",
      "Epoch 95/100\n",
      "120000/120000 - 0s - loss: 1.5108 - val_loss: 0.4590\n",
      "Epoch 96/100\n",
      "120000/120000 - 0s - loss: 1.5224 - val_loss: 0.4590\n",
      "Epoch 97/100\n",
      "120000/120000 - 0s - loss: 1.5030 - val_loss: 0.4590\n",
      "Epoch 98/100\n",
      "120000/120000 - 0s - loss: 1.5358 - val_loss: 0.4589\n",
      "Epoch 99/100\n",
      "120000/120000 - 0s - loss: 1.4861 - val_loss: 0.4590\n",
      "Epoch 100/100\n",
      "120000/120000 - 0s - loss: 1.5049 - val_loss: 0.4590\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "          epochs=epochs, \n",
    "          batch_size=5000, \n",
    "          verbose=2, \n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.6736981971991173\n"
     ]
    }
   ],
   "source": [
    "# fig, ax = plt.subplots(figsize=(12,8))\n",
    "# ax.set_title('Loss')\n",
    "# ax.plot(np.sqrt(history.history['loss']), label='train')\n",
    "# ax.plot(np.sqrt(history.history['val_loss']), label='test')\n",
    "# ax.legend();\n",
    "y_pred = model.predict(X_test)\n",
    "print(steps, np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.26608697, -0.02349626,  0.27246018, -0.15814119, -0.41994822,\n",
       "         1.49872771]),\n",
       " array([ 0.263269  , -0.0228501 ,  0.3190683 ,  0.00988263,  0.00106928,\n",
       "         0.01340782], dtype=float32))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0], y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 100\n",
    "X, y = get_X_y(orbit, steps, False, True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120000 samples, validate on 30000 samples\n",
      "Epoch 1/100\n",
      "120000/120000 - 0s - loss: 1.6800 - val_loss: 0.5162\n",
      "Epoch 2/100\n",
      "120000/120000 - 0s - loss: 1.6566 - val_loss: 0.5112\n",
      "Epoch 3/100\n",
      "120000/120000 - 0s - loss: 1.6425 - val_loss: 0.5086\n",
      "Epoch 4/100\n",
      "120000/120000 - 0s - loss: 1.6114 - val_loss: 0.5095\n",
      "Epoch 5/100\n",
      "120000/120000 - 0s - loss: 1.6326 - val_loss: 0.5087\n",
      "Epoch 6/100\n",
      "120000/120000 - 0s - loss: 1.6343 - val_loss: 0.5083\n",
      "Epoch 7/100\n",
      "120000/120000 - 0s - loss: 1.6398 - val_loss: 0.5085\n",
      "Epoch 8/100\n",
      "120000/120000 - 0s - loss: 1.6354 - val_loss: 0.5086\n",
      "Epoch 9/100\n",
      "120000/120000 - 0s - loss: 1.6287 - val_loss: 0.5074\n",
      "Epoch 10/100\n",
      "120000/120000 - 0s - loss: 1.6453 - val_loss: 0.5076\n",
      "Epoch 11/100\n",
      "120000/120000 - 0s - loss: 1.6891 - val_loss: 0.5079\n",
      "Epoch 12/100\n",
      "120000/120000 - 0s - loss: 1.6157 - val_loss: 0.5081\n",
      "Epoch 13/100\n",
      "120000/120000 - 0s - loss: 1.5981 - val_loss: 0.5078\n",
      "Epoch 14/100\n",
      "120000/120000 - 0s - loss: 1.6531 - val_loss: 0.5077\n",
      "Epoch 15/100\n",
      "120000/120000 - 0s - loss: 1.6315 - val_loss: 0.5086\n",
      "Epoch 16/100\n",
      "120000/120000 - 0s - loss: 1.6370 - val_loss: 0.5078\n",
      "Epoch 17/100\n",
      "120000/120000 - 0s - loss: 1.6531 - val_loss: 0.5077\n",
      "Epoch 18/100\n",
      "120000/120000 - 0s - loss: 1.6221 - val_loss: 0.5081\n",
      "Epoch 19/100\n",
      "120000/120000 - 0s - loss: 1.6421 - val_loss: 0.5070\n",
      "Epoch 20/100\n",
      "120000/120000 - 0s - loss: 1.6547 - val_loss: 0.5098\n",
      "Epoch 21/100\n",
      "120000/120000 - 0s - loss: 1.6553 - val_loss: 0.5079\n",
      "Epoch 22/100\n",
      "120000/120000 - 0s - loss: 1.6342 - val_loss: 0.5081\n",
      "Epoch 23/100\n",
      "120000/120000 - 0s - loss: 1.6655 - val_loss: 0.5072\n",
      "Epoch 24/100\n",
      "120000/120000 - 0s - loss: 1.6497 - val_loss: 0.5084\n",
      "Epoch 25/100\n",
      "120000/120000 - 0s - loss: 1.6385 - val_loss: 0.5076\n",
      "Epoch 26/100\n",
      "120000/120000 - 0s - loss: 1.6542 - val_loss: 0.5077\n",
      "Epoch 27/100\n",
      "120000/120000 - 0s - loss: 1.6547 - val_loss: 0.5085\n",
      "Epoch 28/100\n",
      "120000/120000 - 0s - loss: 1.6072 - val_loss: 0.5085\n",
      "Epoch 29/100\n",
      "120000/120000 - 0s - loss: 1.6733 - val_loss: 0.5077\n",
      "Epoch 30/100\n",
      "120000/120000 - 0s - loss: 1.6569 - val_loss: 0.5082\n",
      "Epoch 31/100\n",
      "120000/120000 - 0s - loss: 1.6523 - val_loss: 0.5084\n",
      "Epoch 32/100\n",
      "120000/120000 - 0s - loss: 1.6224 - val_loss: 0.5081\n",
      "Epoch 33/100\n",
      "120000/120000 - 0s - loss: 1.6291 - val_loss: 0.5078\n",
      "Epoch 34/100\n",
      "120000/120000 - 0s - loss: 1.6419 - val_loss: 0.5070\n",
      "Epoch 35/100\n",
      "120000/120000 - 0s - loss: 1.6184 - val_loss: 0.5095\n",
      "Epoch 36/100\n",
      "120000/120000 - 0s - loss: 1.5862 - val_loss: 0.5084\n",
      "Epoch 37/100\n",
      "120000/120000 - 0s - loss: 1.6663 - val_loss: 0.5082\n",
      "Epoch 38/100\n",
      "120000/120000 - 0s - loss: 1.6515 - val_loss: 0.5078\n",
      "Epoch 39/100\n",
      "120000/120000 - 0s - loss: 1.6026 - val_loss: 0.5083\n",
      "Epoch 40/100\n",
      "120000/120000 - 0s - loss: 1.6629 - val_loss: 0.5083\n",
      "Epoch 41/100\n",
      "120000/120000 - 0s - loss: 1.6208 - val_loss: 0.5076\n",
      "Epoch 42/100\n",
      "120000/120000 - 0s - loss: 1.6408 - val_loss: 0.5084\n",
      "Epoch 43/100\n",
      "120000/120000 - 0s - loss: 1.6600 - val_loss: 0.5061\n",
      "Epoch 44/100\n",
      "120000/120000 - 0s - loss: 1.6558 - val_loss: 0.5088\n",
      "Epoch 45/100\n",
      "120000/120000 - 0s - loss: 1.6219 - val_loss: 0.5077\n",
      "Epoch 46/100\n",
      "120000/120000 - 0s - loss: 1.6018 - val_loss: 0.5079\n",
      "Epoch 47/100\n",
      "120000/120000 - 0s - loss: 1.6307 - val_loss: 0.5078\n",
      "Epoch 48/100\n",
      "120000/120000 - 0s - loss: 1.6112 - val_loss: 0.5078\n",
      "Epoch 49/100\n",
      "120000/120000 - 0s - loss: 1.6036 - val_loss: 0.5088\n",
      "Epoch 50/100\n",
      "120000/120000 - 0s - loss: 1.6156 - val_loss: 0.5081\n",
      "Epoch 51/100\n",
      "120000/120000 - 0s - loss: 1.6594 - val_loss: 0.5080\n",
      "Epoch 52/100\n",
      "120000/120000 - 0s - loss: 1.6626 - val_loss: 0.5073\n",
      "Epoch 53/100\n",
      "120000/120000 - 0s - loss: 1.6502 - val_loss: 0.5088\n",
      "Epoch 54/100\n",
      "120000/120000 - 0s - loss: 1.6208 - val_loss: 0.5078\n",
      "Epoch 55/100\n",
      "120000/120000 - 0s - loss: 1.5649 - val_loss: 0.5083\n",
      "Epoch 56/100\n",
      "120000/120000 - 0s - loss: 1.6193 - val_loss: 0.5075\n",
      "Epoch 57/100\n",
      "120000/120000 - 0s - loss: 1.6469 - val_loss: 0.5077\n",
      "Epoch 58/100\n",
      "120000/120000 - 0s - loss: 1.6539 - val_loss: 0.5077\n",
      "Epoch 59/100\n",
      "120000/120000 - 0s - loss: 1.6153 - val_loss: 0.5084\n",
      "Epoch 60/100\n",
      "120000/120000 - 0s - loss: 1.6974 - val_loss: 0.5083\n",
      "Epoch 61/100\n",
      "120000/120000 - 0s - loss: 1.6370 - val_loss: 0.5088\n",
      "Epoch 62/100\n",
      "120000/120000 - 0s - loss: 1.6253 - val_loss: 0.5079\n",
      "Epoch 63/100\n",
      "120000/120000 - 0s - loss: 1.6481 - val_loss: 0.5078\n",
      "Epoch 64/100\n",
      "120000/120000 - 0s - loss: 1.6697 - val_loss: 0.5069\n",
      "Epoch 65/100\n",
      "120000/120000 - 0s - loss: 1.6178 - val_loss: 0.5072\n",
      "Epoch 66/100\n",
      "120000/120000 - 0s - loss: 1.6239 - val_loss: 0.5089\n",
      "Epoch 67/100\n",
      "120000/120000 - 0s - loss: 1.6309 - val_loss: 0.5080\n",
      "Epoch 68/100\n",
      "120000/120000 - 0s - loss: 1.6764 - val_loss: 0.5070\n",
      "Epoch 69/100\n",
      "120000/120000 - 0s - loss: 1.6473 - val_loss: 0.5086\n",
      "Epoch 70/100\n",
      "120000/120000 - 0s - loss: 1.6358 - val_loss: 0.5074\n",
      "Epoch 71/100\n",
      "120000/120000 - 0s - loss: 1.6275 - val_loss: 0.5077\n",
      "Epoch 72/100\n",
      "120000/120000 - 0s - loss: 1.6232 - val_loss: 0.5087\n",
      "Epoch 73/100\n",
      "120000/120000 - 0s - loss: 1.6752 - val_loss: 0.5079\n",
      "Epoch 74/100\n",
      "120000/120000 - 0s - loss: 1.6489 - val_loss: 0.5077\n",
      "Epoch 75/100\n",
      "120000/120000 - 0s - loss: 1.6410 - val_loss: 0.5078\n",
      "Epoch 76/100\n",
      "120000/120000 - 0s - loss: 1.6027 - val_loss: 0.5081\n",
      "Epoch 77/100\n",
      "120000/120000 - 0s - loss: 1.6121 - val_loss: 0.5091\n",
      "Epoch 78/100\n",
      "120000/120000 - 0s - loss: 1.5934 - val_loss: 0.5077\n",
      "Epoch 79/100\n",
      "120000/120000 - 0s - loss: 1.6544 - val_loss: 0.5078\n",
      "Epoch 80/100\n",
      "120000/120000 - 0s - loss: 1.6247 - val_loss: 0.5081\n",
      "Epoch 81/100\n",
      "120000/120000 - 0s - loss: 1.6067 - val_loss: 0.5083\n",
      "Epoch 82/100\n",
      "120000/120000 - 0s - loss: 1.6641 - val_loss: 0.5081\n",
      "Epoch 83/100\n",
      "120000/120000 - 0s - loss: 1.6148 - val_loss: 0.5071\n",
      "Epoch 84/100\n",
      "120000/120000 - 0s - loss: 1.6291 - val_loss: 0.5073\n",
      "Epoch 85/100\n",
      "120000/120000 - 0s - loss: 1.6493 - val_loss: 0.5079\n",
      "Epoch 86/100\n",
      "120000/120000 - 0s - loss: 1.6241 - val_loss: 0.5071\n",
      "Epoch 87/100\n",
      "120000/120000 - 0s - loss: 1.6311 - val_loss: 0.5078\n",
      "Epoch 88/100\n",
      "120000/120000 - 0s - loss: 1.6248 - val_loss: 0.5071\n",
      "Epoch 89/100\n",
      "120000/120000 - 0s - loss: 1.6642 - val_loss: 0.5085\n",
      "Epoch 90/100\n",
      "120000/120000 - 0s - loss: 1.6363 - val_loss: 0.5083\n",
      "Epoch 91/100\n",
      "120000/120000 - 0s - loss: 1.6454 - val_loss: 0.5081\n",
      "Epoch 92/100\n",
      "120000/120000 - 0s - loss: 1.6606 - val_loss: 0.5074\n",
      "Epoch 93/100\n",
      "120000/120000 - 0s - loss: 1.6768 - val_loss: 0.5083\n",
      "Epoch 94/100\n",
      "120000/120000 - 0s - loss: 1.6351 - val_loss: 0.5080\n",
      "Epoch 95/100\n",
      "120000/120000 - 0s - loss: 1.6722 - val_loss: 0.5077\n",
      "Epoch 96/100\n",
      "120000/120000 - 0s - loss: 1.6233 - val_loss: 0.5073\n",
      "Epoch 97/100\n",
      "120000/120000 - 0s - loss: 1.5903 - val_loss: 0.5071\n",
      "Epoch 98/100\n",
      "120000/120000 - 0s - loss: 1.6513 - val_loss: 0.5084\n",
      "Epoch 99/100\n",
      "120000/120000 - 0s - loss: 1.6391 - val_loss: 0.5073\n",
      "Epoch 100/100\n",
      "120000/120000 - 0s - loss: 1.6007 - val_loss: 0.5075\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "          epochs=epochs, \n",
    "          batch_size=5000, \n",
    "          verbose=2, \n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.7087378867937281\n"
     ]
    }
   ],
   "source": [
    "# fig, ax = plt.subplots(figsize=(12,8))\n",
    "# ax.set_title('Loss')\n",
    "# ax.plot(np.sqrt(history.history['loss']), label='train')\n",
    "# ax.plot(np.sqrt(history.history['val_loss']), label='test')\n",
    "# ax.legend();\n",
    "y_pred = model.predict(X_test)\n",
    "print(steps, np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.12971355, -0.43622705, -0.80293813,  1.16449215,  0.67082781,\n",
       "         0.28566427]),\n",
       " array([-0.48914886, -0.41010717, -0.6369747 , -0.02621982, -0.0166013 ,\n",
       "        -0.038638  ], dtype=float32))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0], y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 1000\n",
    "X, y = get_X_y(orbit, steps, False, True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120000 samples, validate on 30000 samples\n",
      "Epoch 1/100\n",
      "120000/120000 - 0s - loss: 3.4481 - val_loss: 1.5957\n",
      "Epoch 2/100\n",
      "120000/120000 - 0s - loss: 3.4048 - val_loss: 1.5804\n",
      "Epoch 3/100\n",
      "120000/120000 - 0s - loss: 3.4237 - val_loss: 1.5698\n",
      "Epoch 4/100\n",
      "120000/120000 - 0s - loss: 3.3607 - val_loss: 1.5748\n",
      "Epoch 5/100\n",
      "120000/120000 - 0s - loss: 3.4361 - val_loss: 1.5688\n",
      "Epoch 6/100\n",
      "120000/120000 - 0s - loss: 3.3422 - val_loss: 1.5624\n",
      "Epoch 7/100\n",
      "120000/120000 - 0s - loss: 3.3235 - val_loss: 1.5588\n",
      "Epoch 8/100\n",
      "120000/120000 - 0s - loss: 3.3703 - val_loss: 1.5505\n",
      "Epoch 9/100\n",
      "120000/120000 - 0s - loss: 3.3535 - val_loss: 1.5486\n",
      "Epoch 10/100\n",
      "120000/120000 - 0s - loss: 3.3587 - val_loss: 1.5550\n",
      "Epoch 11/100\n",
      "120000/120000 - 0s - loss: 3.3690 - val_loss: 1.5562\n",
      "Epoch 12/100\n",
      "120000/120000 - 0s - loss: 3.2912 - val_loss: 1.5562\n",
      "Epoch 13/100\n",
      "120000/120000 - 0s - loss: 3.4068 - val_loss: 1.5449\n",
      "Epoch 14/100\n",
      "120000/120000 - 0s - loss: 3.3231 - val_loss: 1.5434\n",
      "Epoch 15/100\n",
      "120000/120000 - 0s - loss: 3.4064 - val_loss: 1.5485\n",
      "Epoch 16/100\n",
      "120000/120000 - 0s - loss: 3.3457 - val_loss: 1.5464\n",
      "Epoch 17/100\n",
      "120000/120000 - 0s - loss: 3.3827 - val_loss: 1.5444\n",
      "Epoch 18/100\n",
      "120000/120000 - 0s - loss: 3.3982 - val_loss: 1.5509\n",
      "Epoch 19/100\n",
      "120000/120000 - 0s - loss: 3.4108 - val_loss: 1.5631\n",
      "Epoch 20/100\n",
      "120000/120000 - 0s - loss: 3.4098 - val_loss: 1.5492\n",
      "Epoch 21/100\n",
      "120000/120000 - 0s - loss: 3.3151 - val_loss: 1.5467\n",
      "Epoch 22/100\n",
      "120000/120000 - 0s - loss: 3.3361 - val_loss: 1.5484\n",
      "Epoch 23/100\n",
      "120000/120000 - 0s - loss: 3.2994 - val_loss: 1.5413\n",
      "Epoch 24/100\n",
      "120000/120000 - 0s - loss: 3.2968 - val_loss: 1.5619\n",
      "Epoch 25/100\n",
      "120000/120000 - 0s - loss: 3.3308 - val_loss: 1.5500\n",
      "Epoch 26/100\n",
      "120000/120000 - 0s - loss: 3.2672 - val_loss: 1.5554\n",
      "Epoch 27/100\n",
      "120000/120000 - 0s - loss: 3.3959 - val_loss: 1.5459\n",
      "Epoch 28/100\n",
      "120000/120000 - 0s - loss: 3.3165 - val_loss: 1.5464\n",
      "Epoch 29/100\n",
      "120000/120000 - 0s - loss: 3.2845 - val_loss: 1.5473\n",
      "Epoch 30/100\n",
      "120000/120000 - 0s - loss: 3.3414 - val_loss: 1.5489\n",
      "Epoch 31/100\n",
      "120000/120000 - 0s - loss: 3.3538 - val_loss: 1.5382\n",
      "Epoch 32/100\n",
      "120000/120000 - 0s - loss: 3.3287 - val_loss: 1.5460\n",
      "Epoch 33/100\n",
      "120000/120000 - 0s - loss: 3.3338 - val_loss: 1.5497\n",
      "Epoch 34/100\n",
      "120000/120000 - 0s - loss: 3.2673 - val_loss: 1.5568\n",
      "Epoch 35/100\n",
      "120000/120000 - 0s - loss: 3.3416 - val_loss: 1.5436\n",
      "Epoch 36/100\n",
      "120000/120000 - 0s - loss: 3.3440 - val_loss: 1.5519\n",
      "Epoch 37/100\n",
      "120000/120000 - 0s - loss: 3.3422 - val_loss: 1.5343\n",
      "Epoch 38/100\n",
      "120000/120000 - 0s - loss: 3.3158 - val_loss: 1.5551\n",
      "Epoch 39/100\n",
      "120000/120000 - 0s - loss: 3.3149 - val_loss: 1.5487\n",
      "Epoch 40/100\n",
      "120000/120000 - 0s - loss: 3.3096 - val_loss: 1.5411\n",
      "Epoch 41/100\n",
      "120000/120000 - 0s - loss: 3.3618 - val_loss: 1.5482\n",
      "Epoch 42/100\n",
      "120000/120000 - 0s - loss: 3.4305 - val_loss: 1.5353\n",
      "Epoch 43/100\n",
      "120000/120000 - 0s - loss: 3.3501 - val_loss: 1.5421\n",
      "Epoch 44/100\n",
      "120000/120000 - 0s - loss: 3.3570 - val_loss: 1.5392\n",
      "Epoch 45/100\n",
      "120000/120000 - 0s - loss: 3.3578 - val_loss: 1.5489\n",
      "Epoch 46/100\n",
      "120000/120000 - 0s - loss: 3.3976 - val_loss: 1.5506\n",
      "Epoch 47/100\n",
      "120000/120000 - 0s - loss: 3.3288 - val_loss: 1.5448\n",
      "Epoch 48/100\n",
      "120000/120000 - 0s - loss: 3.3100 - val_loss: 1.5484\n",
      "Epoch 49/100\n",
      "120000/120000 - 0s - loss: 3.3419 - val_loss: 1.5409\n",
      "Epoch 50/100\n",
      "120000/120000 - 0s - loss: 3.3250 - val_loss: 1.5503\n",
      "Epoch 51/100\n",
      "120000/120000 - 0s - loss: 3.3615 - val_loss: 1.5475\n",
      "Epoch 52/100\n",
      "120000/120000 - 0s - loss: 3.3402 - val_loss: 1.5575\n",
      "Epoch 53/100\n",
      "120000/120000 - 0s - loss: 3.3675 - val_loss: 1.5372\n",
      "Epoch 54/100\n",
      "120000/120000 - 0s - loss: 3.3502 - val_loss: 1.5450\n",
      "Epoch 55/100\n",
      "120000/120000 - 0s - loss: 3.3435 - val_loss: 1.5438\n",
      "Epoch 56/100\n",
      "120000/120000 - 0s - loss: 3.2864 - val_loss: 1.5363\n",
      "Epoch 57/100\n",
      "120000/120000 - 0s - loss: 3.4143 - val_loss: 1.5639\n",
      "Epoch 58/100\n",
      "120000/120000 - 0s - loss: 3.3405 - val_loss: 1.5373\n",
      "Epoch 59/100\n",
      "120000/120000 - 0s - loss: 3.3085 - val_loss: 1.5480\n",
      "Epoch 60/100\n",
      "120000/120000 - 0s - loss: 3.3184 - val_loss: 1.5502\n",
      "Epoch 61/100\n",
      "120000/120000 - 0s - loss: 3.3334 - val_loss: 1.5375\n",
      "Epoch 62/100\n",
      "120000/120000 - 0s - loss: 3.3668 - val_loss: 1.5454\n",
      "Epoch 63/100\n",
      "120000/120000 - 0s - loss: 3.3177 - val_loss: 1.5525\n",
      "Epoch 64/100\n",
      "120000/120000 - 0s - loss: 3.2857 - val_loss: 1.5470\n",
      "Epoch 65/100\n",
      "120000/120000 - 0s - loss: 3.3183 - val_loss: 1.5370\n",
      "Epoch 66/100\n",
      "120000/120000 - 0s - loss: 3.3139 - val_loss: 1.5454\n",
      "Epoch 67/100\n",
      "120000/120000 - 0s - loss: 3.3347 - val_loss: 1.5511\n",
      "Epoch 68/100\n",
      "120000/120000 - 0s - loss: 3.2846 - val_loss: 1.5496\n",
      "Epoch 69/100\n",
      "120000/120000 - 0s - loss: 3.3405 - val_loss: 1.5537\n",
      "Epoch 70/100\n",
      "120000/120000 - 0s - loss: 3.3207 - val_loss: 1.5537\n",
      "Epoch 71/100\n",
      "120000/120000 - 0s - loss: 3.3029 - val_loss: 1.5418\n",
      "Epoch 72/100\n",
      "120000/120000 - 0s - loss: 3.3057 - val_loss: 1.5591\n",
      "Epoch 73/100\n",
      "120000/120000 - 0s - loss: 3.3315 - val_loss: 1.5430\n",
      "Epoch 74/100\n",
      "120000/120000 - 0s - loss: 3.3260 - val_loss: 1.5475\n",
      "Epoch 75/100\n",
      "120000/120000 - 0s - loss: 3.3484 - val_loss: 1.5490\n",
      "Epoch 76/100\n",
      "120000/120000 - 0s - loss: 3.3292 - val_loss: 1.5398\n",
      "Epoch 77/100\n",
      "120000/120000 - 0s - loss: 3.3298 - val_loss: 1.5500\n",
      "Epoch 78/100\n",
      "120000/120000 - 0s - loss: 3.4083 - val_loss: 1.5527\n",
      "Epoch 79/100\n",
      "120000/120000 - 0s - loss: 3.3670 - val_loss: 1.5432\n",
      "Epoch 80/100\n",
      "120000/120000 - 0s - loss: 3.3036 - val_loss: 1.5408\n",
      "Epoch 81/100\n",
      "120000/120000 - 0s - loss: 3.3072 - val_loss: 1.5494\n",
      "Epoch 82/100\n",
      "120000/120000 - 0s - loss: 3.3642 - val_loss: 1.5375\n",
      "Epoch 83/100\n",
      "120000/120000 - 0s - loss: 3.3214 - val_loss: 1.5488\n",
      "Epoch 84/100\n",
      "120000/120000 - 0s - loss: 3.3547 - val_loss: 1.5436\n",
      "Epoch 85/100\n",
      "120000/120000 - 0s - loss: 3.3931 - val_loss: 1.5451\n",
      "Epoch 86/100\n",
      "120000/120000 - 0s - loss: 3.3376 - val_loss: 1.5451\n",
      "Epoch 87/100\n",
      "120000/120000 - 0s - loss: 3.3414 - val_loss: 1.5428\n",
      "Epoch 88/100\n",
      "120000/120000 - 0s - loss: 3.3816 - val_loss: 1.5531\n",
      "Epoch 89/100\n",
      "120000/120000 - 0s - loss: 3.2965 - val_loss: 1.5460\n",
      "Epoch 90/100\n",
      "120000/120000 - 0s - loss: 3.3364 - val_loss: 1.5375\n",
      "Epoch 91/100\n",
      "120000/120000 - 0s - loss: 3.4076 - val_loss: 1.5375\n",
      "Epoch 92/100\n",
      "120000/120000 - 0s - loss: 3.3122 - val_loss: 1.5555\n",
      "Epoch 93/100\n",
      "120000/120000 - 0s - loss: 3.3298 - val_loss: 1.5493\n",
      "Epoch 94/100\n",
      "120000/120000 - 0s - loss: 3.3175 - val_loss: 1.5407\n",
      "Epoch 95/100\n",
      "120000/120000 - 0s - loss: 3.3112 - val_loss: 1.5461\n",
      "Epoch 96/100\n",
      "120000/120000 - 0s - loss: 3.3604 - val_loss: 1.5416\n",
      "Epoch 97/100\n",
      "120000/120000 - 0s - loss: 3.3805 - val_loss: 1.5418\n",
      "Epoch 98/100\n",
      "120000/120000 - 0s - loss: 3.3651 - val_loss: 1.5454\n",
      "Epoch 99/100\n",
      "120000/120000 - 0s - loss: 3.3544 - val_loss: 1.5375\n",
      "Epoch 100/100\n",
      "120000/120000 - 0s - loss: 3.3210 - val_loss: 1.5399\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "          epochs=epochs, \n",
    "          batch_size=5000, \n",
    "          verbose=2, \n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1.2318787586011237\n"
     ]
    }
   ],
   "source": [
    "# fig, ax = plt.subplots(figsize=(12,8))\n",
    "# ax.set_title('Loss')\n",
    "# ax.plot(np.sqrt(history.history['loss']), label='train')\n",
    "# ax.plot(np.sqrt(history.history['val_loss']), label='test')\n",
    "# ax.legend();\n",
    "y_pred = model.predict(X_test)\n",
    "print(steps, np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.14316453, -0.40070764,  0.48438827,  0.46492697, -0.26274416,\n",
       "         0.98961032]),\n",
       " array([-0.68804413, -1.3492872 ,  1.3039368 , -0.02815423, -0.05219495,\n",
       "         0.05298544], dtype=float32))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0], y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p36)",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
