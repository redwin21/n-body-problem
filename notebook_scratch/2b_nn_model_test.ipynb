{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "from transform import get_X_y\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow modules. tensorflow was run on a docker container\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "# tf.config.threading.set_intra_op_parallelism_threads(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import sklearn modules\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbit = pd.read_csv('../data/samples_2_bodies_3_dim_1_m_com.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sim_id</th>\n",
       "      <th>m_1</th>\n",
       "      <th>m_2</th>\n",
       "      <th>rx_1_0</th>\n",
       "      <th>ry_1_0</th>\n",
       "      <th>rz_1_0</th>\n",
       "      <th>rx_2_0</th>\n",
       "      <th>ry_2_0</th>\n",
       "      <th>rz_2_0</th>\n",
       "      <th>vx_1_0</th>\n",
       "      <th>...</th>\n",
       "      <th>rz_1_1000</th>\n",
       "      <th>rx_2_1000</th>\n",
       "      <th>ry_2_1000</th>\n",
       "      <th>rz_2_1000</th>\n",
       "      <th>vx_1_1000</th>\n",
       "      <th>vy_1_1000</th>\n",
       "      <th>vz_1_1000</th>\n",
       "      <th>vx_2_1000</th>\n",
       "      <th>vy_2_1000</th>\n",
       "      <th>vz_2_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.072812</td>\n",
       "      <td>0.339681</td>\n",
       "      <td>0.234807</td>\n",
       "      <td>-0.072812</td>\n",
       "      <td>-0.339681</td>\n",
       "      <td>-0.234807</td>\n",
       "      <td>0.032668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245414</td>\n",
       "      <td>-0.062839</td>\n",
       "      <td>-0.156803</td>\n",
       "      <td>-0.245414</td>\n",
       "      <td>-0.104210</td>\n",
       "      <td>-0.721673</td>\n",
       "      <td>-0.262195</td>\n",
       "      <td>0.104210</td>\n",
       "      <td>0.721673</td>\n",
       "      <td>0.262195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.054407</td>\n",
       "      <td>0.105241</td>\n",
       "      <td>0.222055</td>\n",
       "      <td>-0.054407</td>\n",
       "      <td>-0.105241</td>\n",
       "      <td>-0.222055</td>\n",
       "      <td>-0.151459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>-0.017101</td>\n",
       "      <td>-0.250963</td>\n",
       "      <td>-0.001457</td>\n",
       "      <td>0.167632</td>\n",
       "      <td>0.763737</td>\n",
       "      <td>0.546329</td>\n",
       "      <td>-0.167632</td>\n",
       "      <td>-0.763737</td>\n",
       "      <td>-0.546329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015466</td>\n",
       "      <td>-0.034834</td>\n",
       "      <td>0.083430</td>\n",
       "      <td>-0.015466</td>\n",
       "      <td>0.034834</td>\n",
       "      <td>-0.083430</td>\n",
       "      <td>-0.452646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080874</td>\n",
       "      <td>-0.039404</td>\n",
       "      <td>-0.331130</td>\n",
       "      <td>-0.080874</td>\n",
       "      <td>0.128510</td>\n",
       "      <td>0.343728</td>\n",
       "      <td>0.494653</td>\n",
       "      <td>-0.128510</td>\n",
       "      <td>-0.343728</td>\n",
       "      <td>-0.494653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.060140</td>\n",
       "      <td>0.364899</td>\n",
       "      <td>0.167492</td>\n",
       "      <td>-0.060140</td>\n",
       "      <td>-0.364899</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>0.083064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261195</td>\n",
       "      <td>-0.074577</td>\n",
       "      <td>-0.281935</td>\n",
       "      <td>-0.261195</td>\n",
       "      <td>-0.013481</td>\n",
       "      <td>-0.439943</td>\n",
       "      <td>0.074785</td>\n",
       "      <td>0.013481</td>\n",
       "      <td>0.439943</td>\n",
       "      <td>-0.074785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017181</td>\n",
       "      <td>0.251330</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>-0.017181</td>\n",
       "      <td>-0.251330</td>\n",
       "      <td>-0.001720</td>\n",
       "      <td>0.167503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181902</td>\n",
       "      <td>-0.063202</td>\n",
       "      <td>-0.364724</td>\n",
       "      <td>-0.181902</td>\n",
       "      <td>0.074315</td>\n",
       "      <td>-0.030131</td>\n",
       "      <td>0.357845</td>\n",
       "      <td>-0.074315</td>\n",
       "      <td>0.030131</td>\n",
       "      <td>-0.357845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.056611</td>\n",
       "      <td>0.192364</td>\n",
       "      <td>-0.247187</td>\n",
       "      <td>0.056611</td>\n",
       "      <td>-0.192364</td>\n",
       "      <td>0.247187</td>\n",
       "      <td>-0.214536</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125396</td>\n",
       "      <td>0.077384</td>\n",
       "      <td>-0.004295</td>\n",
       "      <td>0.125396</td>\n",
       "      <td>0.130841</td>\n",
       "      <td>-1.165302</td>\n",
       "      <td>1.163385</td>\n",
       "      <td>-0.130841</td>\n",
       "      <td>1.165302</td>\n",
       "      <td>-1.163385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.062381</td>\n",
       "      <td>-0.046865</td>\n",
       "      <td>-0.059740</td>\n",
       "      <td>0.062381</td>\n",
       "      <td>0.046865</td>\n",
       "      <td>0.059740</td>\n",
       "      <td>0.604474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126458</td>\n",
       "      <td>-0.132333</td>\n",
       "      <td>-0.099748</td>\n",
       "      <td>-0.126458</td>\n",
       "      <td>0.632941</td>\n",
       "      <td>1.154271</td>\n",
       "      <td>0.048515</td>\n",
       "      <td>-0.632941</td>\n",
       "      <td>-1.154271</td>\n",
       "      <td>-0.048515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250455</td>\n",
       "      <td>0.441298</td>\n",
       "      <td>0.031888</td>\n",
       "      <td>-0.250455</td>\n",
       "      <td>-0.441298</td>\n",
       "      <td>-0.031888</td>\n",
       "      <td>0.071420</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021397</td>\n",
       "      <td>-0.256480</td>\n",
       "      <td>-0.517709</td>\n",
       "      <td>0.021397</td>\n",
       "      <td>-0.002030</td>\n",
       "      <td>0.345303</td>\n",
       "      <td>-0.286874</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>-0.345303</td>\n",
       "      <td>0.286874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.117538</td>\n",
       "      <td>0.560847</td>\n",
       "      <td>-0.275648</td>\n",
       "      <td>-0.117538</td>\n",
       "      <td>-0.560847</td>\n",
       "      <td>0.275648</td>\n",
       "      <td>-0.211689</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294678</td>\n",
       "      <td>-0.076410</td>\n",
       "      <td>-0.505170</td>\n",
       "      <td>0.294678</td>\n",
       "      <td>-0.231047</td>\n",
       "      <td>-0.354711</td>\n",
       "      <td>-0.072457</td>\n",
       "      <td>0.231047</td>\n",
       "      <td>0.354711</td>\n",
       "      <td>0.072457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.088238</td>\n",
       "      <td>0.522712</td>\n",
       "      <td>-0.290462</td>\n",
       "      <td>-0.088238</td>\n",
       "      <td>-0.522712</td>\n",
       "      <td>0.290462</td>\n",
       "      <td>-0.226049</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.300877</td>\n",
       "      <td>-0.044721</td>\n",
       "      <td>-0.451968</td>\n",
       "      <td>0.300877</td>\n",
       "      <td>-0.242035</td>\n",
       "      <td>-0.442254</td>\n",
       "      <td>-0.017841</td>\n",
       "      <td>0.242035</td>\n",
       "      <td>0.442254</td>\n",
       "      <td>0.017841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sim_id  m_1  m_2    rx_1_0    ry_1_0    rz_1_0    rx_2_0    ry_2_0  \\\n",
       "0          0.0  1.0  1.0  0.072812  0.339681  0.234807 -0.072812 -0.339681   \n",
       "1          0.0  1.0  1.0  0.054407  0.105241  0.222055 -0.054407 -0.105241   \n",
       "2          0.0  1.0  1.0  0.015466 -0.034834  0.083430 -0.015466  0.034834   \n",
       "3          0.0  1.0  1.0  0.060140  0.364899  0.167492 -0.060140 -0.364899   \n",
       "4          0.0  1.0  1.0  0.017181  0.251330  0.001720 -0.017181 -0.251330   \n",
       "...        ...  ...  ...       ...       ...       ...       ...       ...   \n",
       "199995  1999.0  1.0  1.0 -0.056611  0.192364 -0.247187  0.056611 -0.192364   \n",
       "199996  1999.0  1.0  1.0 -0.062381 -0.046865 -0.059740  0.062381  0.046865   \n",
       "199997  1999.0  1.0  1.0  0.250455  0.441298  0.031888 -0.250455 -0.441298   \n",
       "199998  1999.0  1.0  1.0  0.117538  0.560847 -0.275648 -0.117538 -0.560847   \n",
       "199999  1999.0  1.0  1.0  0.088238  0.522712 -0.290462 -0.088238 -0.522712   \n",
       "\n",
       "          rz_2_0    vx_1_0  ...  rz_1_1000  rx_2_1000  ry_2_1000  rz_2_1000  \\\n",
       "0      -0.234807  0.032668  ...   0.245414  -0.062839  -0.156803  -0.245414   \n",
       "1      -0.222055 -0.151459  ...   0.001457  -0.017101  -0.250963  -0.001457   \n",
       "2      -0.083430 -0.452646  ...   0.080874  -0.039404  -0.331130  -0.080874   \n",
       "3      -0.167492  0.083064  ...   0.261195  -0.074577  -0.281935  -0.261195   \n",
       "4      -0.001720  0.167503  ...   0.181902  -0.063202  -0.364724  -0.181902   \n",
       "...          ...       ...  ...        ...        ...        ...        ...   \n",
       "199995  0.247187 -0.214536  ...  -0.125396   0.077384  -0.004295   0.125396   \n",
       "199996  0.059740  0.604474  ...   0.126458  -0.132333  -0.099748  -0.126458   \n",
       "199997 -0.031888  0.071420  ...  -0.021397  -0.256480  -0.517709   0.021397   \n",
       "199998  0.275648 -0.211689  ...  -0.294678  -0.076410  -0.505170   0.294678   \n",
       "199999  0.290462 -0.226049  ...  -0.300877  -0.044721  -0.451968   0.300877   \n",
       "\n",
       "        vx_1_1000  vy_1_1000  vz_1_1000  vx_2_1000  vy_2_1000  vz_2_1000  \n",
       "0       -0.104210  -0.721673  -0.262195   0.104210   0.721673   0.262195  \n",
       "1        0.167632   0.763737   0.546329  -0.167632  -0.763737  -0.546329  \n",
       "2        0.128510   0.343728   0.494653  -0.128510  -0.343728  -0.494653  \n",
       "3       -0.013481  -0.439943   0.074785   0.013481   0.439943  -0.074785  \n",
       "4        0.074315  -0.030131   0.357845  -0.074315   0.030131  -0.357845  \n",
       "...           ...        ...        ...        ...        ...        ...  \n",
       "199995   0.130841  -1.165302   1.163385  -0.130841   1.165302  -1.163385  \n",
       "199996   0.632941   1.154271   0.048515  -0.632941  -1.154271  -0.048515  \n",
       "199997  -0.002030   0.345303  -0.286874   0.002030  -0.345303   0.286874  \n",
       "199998  -0.231047  -0.354711  -0.072457   0.231047   0.354711   0.072457  \n",
       "199999  -0.242035  -0.442254  -0.017841   0.242035   0.442254   0.017841  \n",
       "\n",
       "[200000 rows x 51 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 10\n",
    "X, y = get_X_y(orbit, steps, False, True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create and compile neural network\n",
    "\n",
    "n_samples, n_feats = X_train.shape\n",
    "_, n_outputs = y_train.shape\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "hidden_units = n_feats\n",
    "epochs=100\n",
    "learning_rate = 0.1\n",
    "decay_rate = learning_rate / epochs\n",
    "momentum = 0.8\n",
    "\n",
    "scale = 10\n",
    "\n",
    "\n",
    "hidden_layer = Dense(units=hidden_units,\n",
    "                input_dim=n_feats,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='relu')\n",
    "\n",
    "hidden_layer2 = Dense(units=hidden_units*scale,\n",
    "                input_dim=hidden_units,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='relu')\n",
    "\n",
    "hidden_layer3 = Dense(units=hidden_units*scale,\n",
    "                input_dim=hidden_units*scale,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='relu')\n",
    "\n",
    "hidden_layer4 = Dense(units=n_outputs,\n",
    "                input_dim=hidden_units*scale,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='relu')\n",
    "\n",
    "output_layer = Dense(units=n_outputs,\n",
    "                input_dim=hidden_units,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='linear')\n",
    "\n",
    "model.add(hidden_layer)\n",
    "# model.add(Dropout(rate=0.1))\n",
    "# model.add(hidden_layer2)\n",
    "# model.add(Dropout(rate=0.1))\n",
    "# model.add(hidden_layer3)\n",
    "# model.add(Dropout(rate=0.1))\n",
    "# model.add(hidden_layer3)\n",
    "# model.add(Dropout(rate=0.1))\n",
    "# model.add(hidden_layer3)\n",
    "# model.add(Dropout(rate=0.1))\n",
    "# model.add(hidden_layer3)\n",
    "# model.add(Dropout(rate=0.1))\n",
    "# model.add(hidden_layer3)\n",
    "# model.add(Dropout(rate=0.1))\n",
    "# model.add(hidden_layer3)\n",
    "# model.add(Dropout(rate=0.1))\n",
    "# model.add(hidden_layer4)\n",
    "# model.add(Dropout(rate=0.1))\n",
    "model.add(output_layer)\n",
    "model.add(Dropout(rate=0.1))\n",
    "\n",
    "sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "# sgd = SGD(lr=learning_rate)\n",
    "model.compile(loss='mean_squared_error', \n",
    "              optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120000 samples, validate on 30000 samples\n",
      "Epoch 1/100\n",
      "120000/120000 - 1s - loss: 5.0919 - val_loss: 0.6448\n",
      "Epoch 2/100\n",
      "120000/120000 - 0s - loss: 1.5528 - val_loss: 0.4618\n",
      "Epoch 3/100\n",
      "120000/120000 - 0s - loss: 1.5055 - val_loss: 0.4584\n",
      "Epoch 4/100\n",
      "120000/120000 - 0s - loss: 1.5316 - val_loss: 0.4584\n",
      "Epoch 5/100\n",
      "120000/120000 - 0s - loss: 1.5225 - val_loss: 0.4585\n",
      "Epoch 6/100\n",
      "120000/120000 - 0s - loss: 1.5113 - val_loss: 0.4584\n",
      "Epoch 7/100\n",
      "120000/120000 - 0s - loss: 1.5193 - val_loss: 0.4584\n",
      "Epoch 8/100\n",
      "120000/120000 - 0s - loss: 1.5288 - val_loss: 0.4581\n",
      "Epoch 9/100\n",
      "120000/120000 - 0s - loss: 1.5257 - val_loss: 0.4583\n",
      "Epoch 10/100\n",
      "120000/120000 - 0s - loss: 1.5193 - val_loss: 0.4584\n",
      "Epoch 11/100\n",
      "120000/120000 - 0s - loss: 1.5267 - val_loss: 0.4584\n",
      "Epoch 12/100\n",
      "120000/120000 - 0s - loss: 1.5093 - val_loss: 0.4583\n",
      "Epoch 13/100\n",
      "120000/120000 - 0s - loss: 1.5447 - val_loss: 0.4583\n",
      "Epoch 14/100\n",
      "120000/120000 - 0s - loss: 1.5172 - val_loss: 0.4583\n",
      "Epoch 15/100\n",
      "120000/120000 - 0s - loss: 1.5006 - val_loss: 0.4582\n",
      "Epoch 16/100\n",
      "120000/120000 - 0s - loss: 1.5369 - val_loss: 0.4582\n",
      "Epoch 17/100\n",
      "120000/120000 - 0s - loss: 1.5053 - val_loss: 0.4582\n",
      "Epoch 18/100\n",
      "120000/120000 - 0s - loss: 1.5692 - val_loss: 0.4582\n",
      "Epoch 19/100\n",
      "120000/120000 - 0s - loss: 1.4810 - val_loss: 0.4582\n",
      "Epoch 20/100\n",
      "120000/120000 - 0s - loss: 1.4936 - val_loss: 0.4584\n",
      "Epoch 21/100\n",
      "120000/120000 - 0s - loss: 1.5293 - val_loss: 0.4583\n",
      "Epoch 22/100\n",
      "120000/120000 - 0s - loss: 1.5390 - val_loss: 0.4583\n",
      "Epoch 23/100\n",
      "120000/120000 - 0s - loss: 1.4795 - val_loss: 0.4583\n",
      "Epoch 24/100\n",
      "120000/120000 - 0s - loss: 1.5313 - val_loss: 0.4585\n",
      "Epoch 25/100\n",
      "120000/120000 - 0s - loss: 1.5232 - val_loss: 0.4582\n",
      "Epoch 26/100\n",
      "120000/120000 - 0s - loss: 1.4960 - val_loss: 0.4582\n",
      "Epoch 27/100\n",
      "120000/120000 - 0s - loss: 1.4987 - val_loss: 0.4582\n",
      "Epoch 28/100\n",
      "120000/120000 - 0s - loss: 1.5359 - val_loss: 0.4583\n",
      "Epoch 29/100\n",
      "120000/120000 - 0s - loss: 1.5440 - val_loss: 0.4582\n",
      "Epoch 30/100\n",
      "120000/120000 - 0s - loss: 1.5624 - val_loss: 0.4584\n",
      "Epoch 31/100\n",
      "120000/120000 - 0s - loss: 1.5517 - val_loss: 0.4584\n",
      "Epoch 32/100\n",
      "120000/120000 - 0s - loss: 1.5213 - val_loss: 0.4585\n",
      "Epoch 33/100\n",
      "120000/120000 - 0s - loss: 1.5350 - val_loss: 0.4582\n",
      "Epoch 34/100\n",
      "120000/120000 - 0s - loss: 1.5140 - val_loss: 0.4583\n",
      "Epoch 35/100\n",
      "120000/120000 - 0s - loss: 1.5116 - val_loss: 0.4584\n",
      "Epoch 36/100\n",
      "120000/120000 - 0s - loss: 1.5324 - val_loss: 0.4584\n",
      "Epoch 37/100\n",
      "120000/120000 - 0s - loss: 1.5404 - val_loss: 0.4583\n",
      "Epoch 38/100\n",
      "120000/120000 - 0s - loss: 1.5089 - val_loss: 0.4585\n",
      "Epoch 39/100\n",
      "120000/120000 - 0s - loss: 1.5228 - val_loss: 0.4582\n",
      "Epoch 40/100\n",
      "120000/120000 - 0s - loss: 1.5350 - val_loss: 0.4584\n",
      "Epoch 41/100\n",
      "120000/120000 - 0s - loss: 1.5370 - val_loss: 0.4584\n",
      "Epoch 42/100\n",
      "120000/120000 - 0s - loss: 1.5215 - val_loss: 0.4583\n",
      "Epoch 43/100\n",
      "120000/120000 - 0s - loss: 1.5251 - val_loss: 0.4583\n",
      "Epoch 44/100\n",
      "120000/120000 - 0s - loss: 1.5539 - val_loss: 0.4583\n",
      "Epoch 45/100\n",
      "120000/120000 - 0s - loss: 1.5182 - val_loss: 0.4583\n",
      "Epoch 46/100\n",
      "120000/120000 - 0s - loss: 1.5034 - val_loss: 0.4583\n",
      "Epoch 47/100\n",
      "120000/120000 - 0s - loss: 1.5314 - val_loss: 0.4583\n",
      "Epoch 48/100\n",
      "120000/120000 - 0s - loss: 1.5583 - val_loss: 0.4583\n",
      "Epoch 49/100\n",
      "120000/120000 - 0s - loss: 1.5370 - val_loss: 0.4584\n",
      "Epoch 50/100\n",
      "120000/120000 - 0s - loss: 1.4701 - val_loss: 0.4584\n",
      "Epoch 51/100\n",
      "120000/120000 - 0s - loss: 1.5420 - val_loss: 0.4583\n",
      "Epoch 52/100\n",
      "120000/120000 - 0s - loss: 1.5094 - val_loss: 0.4583\n",
      "Epoch 53/100\n",
      "120000/120000 - 0s - loss: 1.5189 - val_loss: 0.4582\n",
      "Epoch 54/100\n",
      "120000/120000 - 0s - loss: 1.4936 - val_loss: 0.4585\n",
      "Epoch 55/100\n",
      "120000/120000 - 0s - loss: 1.5210 - val_loss: 0.4582\n",
      "Epoch 56/100\n",
      "120000/120000 - 0s - loss: 1.5180 - val_loss: 0.4583\n",
      "Epoch 57/100\n",
      "120000/120000 - 0s - loss: 1.5900 - val_loss: 0.4583\n",
      "Epoch 58/100\n",
      "120000/120000 - 0s - loss: 1.4985 - val_loss: 0.4583\n",
      "Epoch 59/100\n",
      "120000/120000 - 0s - loss: 1.5018 - val_loss: 0.4583\n",
      "Epoch 60/100\n",
      "120000/120000 - 0s - loss: 1.5776 - val_loss: 0.4582\n",
      "Epoch 61/100\n",
      "120000/120000 - 0s - loss: 1.4941 - val_loss: 0.4583\n",
      "Epoch 62/100\n",
      "120000/120000 - 0s - loss: 1.5332 - val_loss: 0.4584\n",
      "Epoch 63/100\n",
      "120000/120000 - 0s - loss: 1.5460 - val_loss: 0.4583\n",
      "Epoch 64/100\n",
      "120000/120000 - 0s - loss: 1.5018 - val_loss: 0.4584\n",
      "Epoch 65/100\n",
      "120000/120000 - 0s - loss: 1.5506 - val_loss: 0.4582\n",
      "Epoch 66/100\n",
      "120000/120000 - 0s - loss: 1.4962 - val_loss: 0.4583\n",
      "Epoch 67/100\n",
      "120000/120000 - 0s - loss: 1.5166 - val_loss: 0.4583\n",
      "Epoch 68/100\n",
      "120000/120000 - 0s - loss: 1.5314 - val_loss: 0.4584\n",
      "Epoch 69/100\n",
      "120000/120000 - 0s - loss: 1.5014 - val_loss: 0.4583\n",
      "Epoch 70/100\n",
      "120000/120000 - 0s - loss: 1.5627 - val_loss: 0.4584\n",
      "Epoch 71/100\n",
      "120000/120000 - 0s - loss: 1.5513 - val_loss: 0.4583\n",
      "Epoch 72/100\n",
      "120000/120000 - 0s - loss: 1.5421 - val_loss: 0.4584\n",
      "Epoch 73/100\n",
      "120000/120000 - 0s - loss: 1.5374 - val_loss: 0.4583\n",
      "Epoch 74/100\n",
      "120000/120000 - 0s - loss: 1.5099 - val_loss: 0.4583\n",
      "Epoch 75/100\n",
      "120000/120000 - 0s - loss: 1.5271 - val_loss: 0.4583\n",
      "Epoch 76/100\n",
      "120000/120000 - 0s - loss: 1.5569 - val_loss: 0.4582\n",
      "Epoch 77/100\n",
      "120000/120000 - 0s - loss: 1.5117 - val_loss: 0.4583\n",
      "Epoch 78/100\n",
      "120000/120000 - 0s - loss: 1.5529 - val_loss: 0.4583\n",
      "Epoch 79/100\n",
      "120000/120000 - 0s - loss: 1.5281 - val_loss: 0.4583\n",
      "Epoch 80/100\n",
      "120000/120000 - 0s - loss: 1.5476 - val_loss: 0.4583\n",
      "Epoch 81/100\n",
      "120000/120000 - 0s - loss: 1.5311 - val_loss: 0.4584\n",
      "Epoch 82/100\n",
      "120000/120000 - 0s - loss: 1.5362 - val_loss: 0.4583\n",
      "Epoch 83/100\n",
      "120000/120000 - 0s - loss: 1.5125 - val_loss: 0.4583\n",
      "Epoch 84/100\n",
      "120000/120000 - 0s - loss: 1.5062 - val_loss: 0.4582\n",
      "Epoch 85/100\n",
      "120000/120000 - 0s - loss: 1.5340 - val_loss: 0.4584\n",
      "Epoch 86/100\n",
      "120000/120000 - 0s - loss: 1.5056 - val_loss: 0.4583\n",
      "Epoch 87/100\n",
      "120000/120000 - 0s - loss: 1.5123 - val_loss: 0.4585\n",
      "Epoch 88/100\n",
      "120000/120000 - 0s - loss: 1.5627 - val_loss: 0.4582\n",
      "Epoch 89/100\n",
      "120000/120000 - 0s - loss: 1.5257 - val_loss: 0.4583\n",
      "Epoch 90/100\n",
      "120000/120000 - 0s - loss: 1.5096 - val_loss: 0.4584\n",
      "Epoch 91/100\n",
      "120000/120000 - 0s - loss: 1.5273 - val_loss: 0.4583\n",
      "Epoch 92/100\n",
      "120000/120000 - 0s - loss: 1.5192 - val_loss: 0.4584\n",
      "Epoch 93/100\n",
      "120000/120000 - 0s - loss: 1.5150 - val_loss: 0.4584\n",
      "Epoch 94/100\n",
      "120000/120000 - 0s - loss: 1.5525 - val_loss: 0.4582\n",
      "Epoch 95/100\n",
      "120000/120000 - 0s - loss: 1.5447 - val_loss: 0.4583\n",
      "Epoch 96/100\n",
      "120000/120000 - 0s - loss: 1.4970 - val_loss: 0.4583\n",
      "Epoch 97/100\n",
      "120000/120000 - 0s - loss: 1.5122 - val_loss: 0.4583\n",
      "Epoch 98/100\n",
      "120000/120000 - 0s - loss: 1.5242 - val_loss: 0.4583\n",
      "Epoch 99/100\n",
      "120000/120000 - 0s - loss: 1.5483 - val_loss: 0.4582\n",
      "Epoch 100/100\n",
      "120000/120000 - 0s - loss: 1.5235 - val_loss: 0.4583\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "          epochs=epochs, \n",
    "          batch_size=5000, \n",
    "          verbose=2, \n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 [0.46569351 0.50055616 0.49530384 0.83313271 0.83056881 0.81280555]\n"
     ]
    }
   ],
   "source": [
    "# fig, ax = plt.subplots(figsize=(12,8))\n",
    "# ax.set_title('Loss')\n",
    "# ax.plot(np.sqrt(history.history['loss']), label='train')\n",
    "# ax.plot(np.sqrt(history.history['val_loss']), label='test')\n",
    "# ax.legend();\n",
    "y_pred = model.predict(X_test)\n",
    "error_10 = np.sqrt(mean_squared_error(y_test, y_pred, multioutput='raw_values'))\n",
    "print(steps, error_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.30473428,  1.43991498, -0.27456941, -0.16877983, -0.00682965,\n",
       "         0.29557322]),\n",
       " array([-0.28559414,  1.2847446 , -0.23912589, -0.01190691,  0.06963748,\n",
       "        -0.0063195 ], dtype=float32))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0], y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 100\n",
    "X, y = get_X_y(orbit, steps, False, True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120000 samples, validate on 30000 samples\n",
      "Epoch 1/100\n",
      "120000/120000 - 0s - loss: 1.6182 - val_loss: 0.5231\n",
      "Epoch 2/100\n",
      "120000/120000 - 0s - loss: 1.6168 - val_loss: 0.5171\n",
      "Epoch 3/100\n",
      "120000/120000 - 0s - loss: 1.6124 - val_loss: 0.5153\n",
      "Epoch 4/100\n",
      "120000/120000 - 0s - loss: 1.6218 - val_loss: 0.5140\n",
      "Epoch 5/100\n",
      "120000/120000 - 0s - loss: 1.6449 - val_loss: 0.5136\n",
      "Epoch 6/100\n",
      "120000/120000 - 0s - loss: 1.6112 - val_loss: 0.5153\n",
      "Epoch 7/100\n",
      "120000/120000 - 0s - loss: 1.6509 - val_loss: 0.5139\n",
      "Epoch 8/100\n",
      "120000/120000 - 0s - loss: 1.6044 - val_loss: 0.5144\n",
      "Epoch 9/100\n",
      "120000/120000 - 0s - loss: 1.6353 - val_loss: 0.5125\n",
      "Epoch 10/100\n",
      "120000/120000 - 0s - loss: 1.6461 - val_loss: 0.5153\n",
      "Epoch 11/100\n",
      "120000/120000 - 0s - loss: 1.6376 - val_loss: 0.5136\n",
      "Epoch 12/100\n",
      "120000/120000 - 0s - loss: 1.6438 - val_loss: 0.5141\n",
      "Epoch 13/100\n",
      "120000/120000 - 0s - loss: 1.5967 - val_loss: 0.5133\n",
      "Epoch 14/100\n",
      "120000/120000 - 0s - loss: 1.6395 - val_loss: 0.5144\n",
      "Epoch 15/100\n",
      "120000/120000 - 0s - loss: 1.6614 - val_loss: 0.5127\n",
      "Epoch 16/100\n",
      "120000/120000 - 0s - loss: 1.6669 - val_loss: 0.5145\n",
      "Epoch 17/100\n",
      "120000/120000 - 0s - loss: 1.6744 - val_loss: 0.5136\n",
      "Epoch 18/100\n",
      "120000/120000 - 0s - loss: 1.6697 - val_loss: 0.5140\n",
      "Epoch 19/100\n",
      "120000/120000 - 0s - loss: 1.6055 - val_loss: 0.5137\n",
      "Epoch 20/100\n",
      "120000/120000 - 0s - loss: 1.6445 - val_loss: 0.5141\n",
      "Epoch 21/100\n",
      "120000/120000 - 0s - loss: 1.6174 - val_loss: 0.5149\n",
      "Epoch 22/100\n",
      "120000/120000 - 0s - loss: 1.5889 - val_loss: 0.5135\n",
      "Epoch 23/100\n",
      "120000/120000 - 0s - loss: 1.6475 - val_loss: 0.5129\n",
      "Epoch 24/100\n",
      "120000/120000 - 0s - loss: 1.6108 - val_loss: 0.5139\n",
      "Epoch 25/100\n",
      "120000/120000 - 0s - loss: 1.6323 - val_loss: 0.5129\n",
      "Epoch 26/100\n",
      "120000/120000 - 0s - loss: 1.6342 - val_loss: 0.5126\n",
      "Epoch 27/100\n",
      "120000/120000 - 0s - loss: 1.6278 - val_loss: 0.5134\n",
      "Epoch 28/100\n",
      "120000/120000 - 0s - loss: 1.6147 - val_loss: 0.5135\n",
      "Epoch 29/100\n",
      "120000/120000 - 0s - loss: 1.6027 - val_loss: 0.5140\n",
      "Epoch 30/100\n",
      "120000/120000 - 0s - loss: 1.6138 - val_loss: 0.5136\n",
      "Epoch 31/100\n",
      "120000/120000 - 0s - loss: 1.6329 - val_loss: 0.5146\n",
      "Epoch 32/100\n",
      "120000/120000 - 0s - loss: 1.5939 - val_loss: 0.5145\n",
      "Epoch 33/100\n",
      "120000/120000 - 0s - loss: 1.6503 - val_loss: 0.5151\n",
      "Epoch 34/100\n",
      "120000/120000 - 0s - loss: 1.6480 - val_loss: 0.5143\n",
      "Epoch 35/100\n",
      "120000/120000 - 0s - loss: 1.6094 - val_loss: 0.5142\n",
      "Epoch 36/100\n",
      "120000/120000 - 0s - loss: 1.6171 - val_loss: 0.5140\n",
      "Epoch 37/100\n",
      "120000/120000 - 0s - loss: 1.6250 - val_loss: 0.5139\n",
      "Epoch 38/100\n",
      "120000/120000 - 0s - loss: 1.6361 - val_loss: 0.5133\n",
      "Epoch 39/100\n",
      "120000/120000 - 0s - loss: 1.5986 - val_loss: 0.5135\n",
      "Epoch 40/100\n",
      "120000/120000 - 0s - loss: 1.5964 - val_loss: 0.5136\n",
      "Epoch 41/100\n",
      "120000/120000 - 0s - loss: 1.6085 - val_loss: 0.5133\n",
      "Epoch 42/100\n",
      "120000/120000 - 0s - loss: 1.6268 - val_loss: 0.5140\n",
      "Epoch 43/100\n",
      "120000/120000 - 0s - loss: 1.6255 - val_loss: 0.5138\n",
      "Epoch 44/100\n",
      "120000/120000 - 0s - loss: 1.6315 - val_loss: 0.5137\n",
      "Epoch 45/100\n",
      "120000/120000 - 0s - loss: 1.6396 - val_loss: 0.5133\n",
      "Epoch 46/100\n",
      "120000/120000 - 0s - loss: 1.6431 - val_loss: 0.5135\n",
      "Epoch 47/100\n",
      "120000/120000 - 0s - loss: 1.6018 - val_loss: 0.5130\n",
      "Epoch 48/100\n",
      "120000/120000 - 0s - loss: 1.6248 - val_loss: 0.5142\n",
      "Epoch 49/100\n",
      "120000/120000 - 0s - loss: 1.6000 - val_loss: 0.5134\n",
      "Epoch 50/100\n",
      "120000/120000 - 0s - loss: 1.5934 - val_loss: 0.5141\n",
      "Epoch 51/100\n",
      "120000/120000 - 0s - loss: 1.5842 - val_loss: 0.5126\n",
      "Epoch 52/100\n",
      "120000/120000 - 0s - loss: 1.6447 - val_loss: 0.5144\n",
      "Epoch 53/100\n",
      "120000/120000 - 0s - loss: 1.6386 - val_loss: 0.5138\n",
      "Epoch 54/100\n",
      "120000/120000 - 0s - loss: 1.6601 - val_loss: 0.5133\n",
      "Epoch 55/100\n",
      "120000/120000 - 0s - loss: 1.6671 - val_loss: 0.5123\n",
      "Epoch 56/100\n",
      "120000/120000 - 0s - loss: 1.6303 - val_loss: 0.5138\n",
      "Epoch 57/100\n",
      "120000/120000 - 0s - loss: 1.6247 - val_loss: 0.5133\n",
      "Epoch 58/100\n",
      "120000/120000 - 0s - loss: 1.6087 - val_loss: 0.5139\n",
      "Epoch 59/100\n",
      "120000/120000 - 0s - loss: 1.6439 - val_loss: 0.5142\n",
      "Epoch 60/100\n",
      "120000/120000 - 0s - loss: 1.6348 - val_loss: 0.5143\n",
      "Epoch 61/100\n",
      "120000/120000 - 0s - loss: 1.5900 - val_loss: 0.5147\n",
      "Epoch 62/100\n",
      "120000/120000 - 0s - loss: 1.6708 - val_loss: 0.5135\n",
      "Epoch 63/100\n",
      "120000/120000 - 0s - loss: 1.6638 - val_loss: 0.5140\n",
      "Epoch 64/100\n",
      "120000/120000 - 0s - loss: 1.6429 - val_loss: 0.5136\n",
      "Epoch 65/100\n",
      "120000/120000 - 0s - loss: 1.6416 - val_loss: 0.5147\n",
      "Epoch 66/100\n",
      "120000/120000 - 0s - loss: 1.6049 - val_loss: 0.5141\n",
      "Epoch 67/100\n",
      "120000/120000 - 0s - loss: 1.6506 - val_loss: 0.5139\n",
      "Epoch 68/100\n",
      "120000/120000 - 0s - loss: 1.6102 - val_loss: 0.5134\n",
      "Epoch 69/100\n",
      "120000/120000 - 0s - loss: 1.6126 - val_loss: 0.5142\n",
      "Epoch 70/100\n",
      "120000/120000 - 0s - loss: 1.6441 - val_loss: 0.5141\n",
      "Epoch 71/100\n",
      "120000/120000 - 0s - loss: 1.6626 - val_loss: 0.5137\n",
      "Epoch 72/100\n",
      "120000/120000 - 0s - loss: 1.6371 - val_loss: 0.5138\n",
      "Epoch 73/100\n",
      "120000/120000 - 0s - loss: 1.6022 - val_loss: 0.5134\n",
      "Epoch 74/100\n",
      "120000/120000 - 0s - loss: 1.6304 - val_loss: 0.5133\n",
      "Epoch 75/100\n",
      "120000/120000 - 0s - loss: 1.6291 - val_loss: 0.5124\n",
      "Epoch 76/100\n",
      "120000/120000 - 0s - loss: 1.6161 - val_loss: 0.5138\n",
      "Epoch 77/100\n",
      "120000/120000 - 0s - loss: 1.6181 - val_loss: 0.5135\n",
      "Epoch 78/100\n",
      "120000/120000 - 0s - loss: 1.6634 - val_loss: 0.5127\n",
      "Epoch 79/100\n",
      "120000/120000 - 0s - loss: 1.6443 - val_loss: 0.5143\n",
      "Epoch 80/100\n",
      "120000/120000 - 0s - loss: 1.5949 - val_loss: 0.5140\n",
      "Epoch 81/100\n",
      "120000/120000 - 0s - loss: 1.6175 - val_loss: 0.5138\n",
      "Epoch 82/100\n",
      "120000/120000 - 0s - loss: 1.6334 - val_loss: 0.5132\n",
      "Epoch 83/100\n",
      "120000/120000 - 0s - loss: 1.6125 - val_loss: 0.5130\n",
      "Epoch 84/100\n",
      "120000/120000 - 0s - loss: 1.6336 - val_loss: 0.5129\n",
      "Epoch 85/100\n",
      "120000/120000 - 0s - loss: 1.6234 - val_loss: 0.5135\n",
      "Epoch 86/100\n",
      "120000/120000 - 0s - loss: 1.6630 - val_loss: 0.5135\n",
      "Epoch 87/100\n",
      "120000/120000 - 0s - loss: 1.6219 - val_loss: 0.5144\n",
      "Epoch 88/100\n",
      "120000/120000 - 0s - loss: 1.6183 - val_loss: 0.5125\n",
      "Epoch 89/100\n",
      "120000/120000 - 0s - loss: 1.6103 - val_loss: 0.5139\n",
      "Epoch 90/100\n",
      "120000/120000 - 0s - loss: 1.6279 - val_loss: 0.5131\n",
      "Epoch 91/100\n",
      "120000/120000 - 0s - loss: 1.6274 - val_loss: 0.5137\n",
      "Epoch 92/100\n",
      "120000/120000 - 0s - loss: 1.6257 - val_loss: 0.5141\n",
      "Epoch 93/100\n",
      "120000/120000 - 0s - loss: 1.6619 - val_loss: 0.5134\n",
      "Epoch 94/100\n",
      "120000/120000 - 0s - loss: 1.6250 - val_loss: 0.5140\n",
      "Epoch 95/100\n",
      "120000/120000 - 0s - loss: 1.6265 - val_loss: 0.5133\n",
      "Epoch 96/100\n",
      "120000/120000 - 0s - loss: 1.6679 - val_loss: 0.5135\n",
      "Epoch 97/100\n",
      "120000/120000 - 0s - loss: 1.6328 - val_loss: 0.5133\n",
      "Epoch 98/100\n",
      "120000/120000 - 0s - loss: 1.6637 - val_loss: 0.5138\n",
      "Epoch 99/100\n",
      "120000/120000 - 0s - loss: 1.6292 - val_loss: 0.5135\n",
      "Epoch 100/100\n",
      "120000/120000 - 0s - loss: 1.6528 - val_loss: 0.5131\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "          epochs=epochs, \n",
    "          batch_size=5000, \n",
    "          verbose=2, \n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 [0.55043457 0.58400466 0.5762359  0.82846864 0.84025464 0.82381291]\n"
     ]
    }
   ],
   "source": [
    "# fig, ax = plt.subplots(figsize=(12,8))\n",
    "# ax.set_title('Loss')\n",
    "# ax.plot(np.sqrt(history.history['loss']), label='train')\n",
    "# ax.plot(np.sqrt(history.history['val_loss']), label='test')\n",
    "# ax.legend();\n",
    "y_pred = model.predict(X_test)\n",
    "error_100 = np.sqrt(mean_squared_error(y_test, y_pred, multioutput='raw_values'))\n",
    "print(steps, error_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.07684949,  1.44293991, -0.66873498,  0.44161339, -0.26461157,\n",
       "         0.27543053]),\n",
       " array([ 2.5195193 ,  1.384956  , -0.5703058 ,  0.12889645,  0.07012776,\n",
       "        -0.02369317], dtype=float32))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0], y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 1000\n",
    "X, y = get_X_y(orbit, steps, False, True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120000 samples, validate on 30000 samples\n",
      "Epoch 1/100\n",
      "120000/120000 - 0s - loss: 3.5394 - val_loss: 1.5640\n",
      "Epoch 2/100\n",
      "120000/120000 - 0s - loss: 3.3160 - val_loss: 1.5721\n",
      "Epoch 3/100\n",
      "120000/120000 - 0s - loss: 3.3825 - val_loss: 1.5551\n",
      "Epoch 4/100\n",
      "120000/120000 - 0s - loss: 3.3788 - val_loss: 1.5495\n",
      "Epoch 5/100\n",
      "120000/120000 - 0s - loss: 3.3677 - val_loss: 1.5507\n",
      "Epoch 6/100\n",
      "120000/120000 - 0s - loss: 3.2844 - val_loss: 1.5443\n",
      "Epoch 7/100\n",
      "120000/120000 - 0s - loss: 3.3606 - val_loss: 1.5372\n",
      "Epoch 8/100\n",
      "120000/120000 - 0s - loss: 3.3605 - val_loss: 1.5401\n",
      "Epoch 9/100\n",
      "120000/120000 - 0s - loss: 3.3176 - val_loss: 1.5483\n",
      "Epoch 10/100\n",
      "120000/120000 - 0s - loss: 3.3331 - val_loss: 1.5207\n",
      "Epoch 11/100\n",
      "120000/120000 - 0s - loss: 3.3359 - val_loss: 1.5382\n",
      "Epoch 12/100\n",
      "120000/120000 - 0s - loss: 3.2692 - val_loss: 1.5429\n",
      "Epoch 13/100\n",
      "120000/120000 - 0s - loss: 3.3312 - val_loss: 1.5320\n",
      "Epoch 14/100\n",
      "120000/120000 - 0s - loss: 3.3225 - val_loss: 1.5242\n",
      "Epoch 15/100\n",
      "120000/120000 - 0s - loss: 3.3100 - val_loss: 1.5325\n",
      "Epoch 16/100\n",
      "120000/120000 - 0s - loss: 3.3878 - val_loss: 1.5227\n",
      "Epoch 17/100\n",
      "120000/120000 - 0s - loss: 3.3538 - val_loss: 1.5486\n",
      "Epoch 18/100\n",
      "120000/120000 - 0s - loss: 3.3238 - val_loss: 1.5278\n",
      "Epoch 19/100\n",
      "120000/120000 - 0s - loss: 3.3655 - val_loss: 1.5305\n",
      "Epoch 20/100\n",
      "120000/120000 - 0s - loss: 3.3754 - val_loss: 1.5339\n",
      "Epoch 21/100\n",
      "120000/120000 - 0s - loss: 3.3940 - val_loss: 1.5323\n",
      "Epoch 22/100\n",
      "120000/120000 - 0s - loss: 3.3202 - val_loss: 1.5376\n",
      "Epoch 23/100\n",
      "120000/120000 - 0s - loss: 3.2864 - val_loss: 1.5318\n",
      "Epoch 24/100\n",
      "120000/120000 - 0s - loss: 3.3643 - val_loss: 1.5267\n",
      "Epoch 25/100\n",
      "120000/120000 - 0s - loss: 3.3637 - val_loss: 1.5331\n",
      "Epoch 26/100\n",
      "120000/120000 - 0s - loss: 3.3386 - val_loss: 1.5395\n",
      "Epoch 27/100\n",
      "120000/120000 - 0s - loss: 3.3313 - val_loss: 1.5314\n",
      "Epoch 28/100\n",
      "120000/120000 - 0s - loss: 3.2992 - val_loss: 1.5294\n",
      "Epoch 29/100\n",
      "120000/120000 - 0s - loss: 3.3224 - val_loss: 1.5264\n",
      "Epoch 30/100\n",
      "120000/120000 - 0s - loss: 3.3301 - val_loss: 1.5283\n",
      "Epoch 31/100\n",
      "120000/120000 - 0s - loss: 3.3355 - val_loss: 1.5309\n",
      "Epoch 32/100\n",
      "120000/120000 - 0s - loss: 3.3301 - val_loss: 1.5337\n",
      "Epoch 33/100\n",
      "120000/120000 - 0s - loss: 3.2905 - val_loss: 1.5281\n",
      "Epoch 34/100\n",
      "120000/120000 - 0s - loss: 3.2911 - val_loss: 1.5291\n",
      "Epoch 35/100\n",
      "120000/120000 - 0s - loss: 3.2924 - val_loss: 1.5326\n",
      "Epoch 36/100\n",
      "120000/120000 - 0s - loss: 3.2852 - val_loss: 1.5247\n",
      "Epoch 37/100\n",
      "120000/120000 - 0s - loss: 3.3286 - val_loss: 1.5325\n",
      "Epoch 38/100\n",
      "120000/120000 - 0s - loss: 3.3230 - val_loss: 1.5239\n",
      "Epoch 39/100\n",
      "120000/120000 - 0s - loss: 3.3285 - val_loss: 1.5288\n",
      "Epoch 40/100\n",
      "120000/120000 - 0s - loss: 3.2384 - val_loss: 1.5322\n",
      "Epoch 41/100\n",
      "120000/120000 - 0s - loss: 3.3595 - val_loss: 1.5312\n",
      "Epoch 42/100\n",
      "120000/120000 - 0s - loss: 3.3143 - val_loss: 1.5320\n",
      "Epoch 43/100\n",
      "120000/120000 - 0s - loss: 3.3166 - val_loss: 1.5200\n",
      "Epoch 44/100\n",
      "120000/120000 - 0s - loss: 3.3209 - val_loss: 1.5327\n",
      "Epoch 45/100\n",
      "120000/120000 - 0s - loss: 3.3896 - val_loss: 1.5253\n",
      "Epoch 46/100\n",
      "120000/120000 - 0s - loss: 3.3622 - val_loss: 1.5265\n",
      "Epoch 47/100\n",
      "120000/120000 - 0s - loss: 3.3379 - val_loss: 1.5262\n",
      "Epoch 48/100\n",
      "120000/120000 - 0s - loss: 3.2871 - val_loss: 1.5272\n",
      "Epoch 49/100\n",
      "120000/120000 - 0s - loss: 3.3249 - val_loss: 1.5304\n",
      "Epoch 50/100\n",
      "120000/120000 - 0s - loss: 3.3495 - val_loss: 1.5136\n",
      "Epoch 51/100\n",
      "120000/120000 - 0s - loss: 3.3994 - val_loss: 1.5293\n",
      "Epoch 52/100\n",
      "120000/120000 - 0s - loss: 3.3299 - val_loss: 1.5306\n",
      "Epoch 53/100\n",
      "120000/120000 - 0s - loss: 3.2849 - val_loss: 1.5407\n",
      "Epoch 54/100\n",
      "120000/120000 - 0s - loss: 3.3561 - val_loss: 1.5238\n",
      "Epoch 55/100\n",
      "120000/120000 - 0s - loss: 3.3139 - val_loss: 1.5388\n",
      "Epoch 56/100\n",
      "120000/120000 - 0s - loss: 3.3141 - val_loss: 1.5257\n",
      "Epoch 57/100\n",
      "120000/120000 - 0s - loss: 3.4083 - val_loss: 1.5242\n",
      "Epoch 58/100\n",
      "120000/120000 - 0s - loss: 3.2408 - val_loss: 1.5237\n",
      "Epoch 59/100\n",
      "120000/120000 - 0s - loss: 3.3552 - val_loss: 1.5223\n",
      "Epoch 60/100\n",
      "120000/120000 - 0s - loss: 3.2996 - val_loss: 1.5348\n",
      "Epoch 61/100\n",
      "120000/120000 - 0s - loss: 3.3368 - val_loss: 1.5210\n",
      "Epoch 62/100\n",
      "120000/120000 - 0s - loss: 3.3110 - val_loss: 1.5189\n",
      "Epoch 63/100\n",
      "120000/120000 - 0s - loss: 3.3727 - val_loss: 1.5204\n",
      "Epoch 64/100\n",
      "120000/120000 - 0s - loss: 3.2921 - val_loss: 1.5171\n",
      "Epoch 65/100\n",
      "120000/120000 - 0s - loss: 3.2869 - val_loss: 1.5291\n",
      "Epoch 66/100\n",
      "120000/120000 - 0s - loss: 3.3553 - val_loss: 1.5208\n",
      "Epoch 67/100\n",
      "120000/120000 - 0s - loss: 3.2501 - val_loss: 1.5318\n",
      "Epoch 68/100\n",
      "120000/120000 - 0s - loss: 3.2825 - val_loss: 1.5303\n",
      "Epoch 69/100\n",
      "120000/120000 - 0s - loss: 3.3213 - val_loss: 1.5374\n",
      "Epoch 70/100\n",
      "120000/120000 - 0s - loss: 3.3380 - val_loss: 1.5272\n",
      "Epoch 71/100\n",
      "120000/120000 - 0s - loss: 3.3229 - val_loss: 1.5244\n",
      "Epoch 72/100\n",
      "120000/120000 - 0s - loss: 3.2992 - val_loss: 1.5340\n",
      "Epoch 73/100\n",
      "120000/120000 - 0s - loss: 3.3174 - val_loss: 1.5328\n",
      "Epoch 74/100\n",
      "120000/120000 - 0s - loss: 3.2916 - val_loss: 1.5198\n",
      "Epoch 75/100\n",
      "120000/120000 - 0s - loss: 3.2760 - val_loss: 1.5353\n",
      "Epoch 76/100\n",
      "120000/120000 - 0s - loss: 3.3172 - val_loss: 1.5347\n",
      "Epoch 77/100\n",
      "120000/120000 - 0s - loss: 3.3599 - val_loss: 1.5267\n",
      "Epoch 78/100\n",
      "120000/120000 - 0s - loss: 3.3001 - val_loss: 1.5296\n",
      "Epoch 79/100\n",
      "120000/120000 - 0s - loss: 3.3108 - val_loss: 1.5266\n",
      "Epoch 80/100\n",
      "120000/120000 - 0s - loss: 3.3125 - val_loss: 1.5270\n",
      "Epoch 81/100\n",
      "120000/120000 - 0s - loss: 3.3584 - val_loss: 1.5261\n",
      "Epoch 82/100\n",
      "120000/120000 - 0s - loss: 3.3247 - val_loss: 1.5335\n",
      "Epoch 83/100\n",
      "120000/120000 - 0s - loss: 3.3438 - val_loss: 1.5308\n",
      "Epoch 84/100\n",
      "120000/120000 - 0s - loss: 3.3067 - val_loss: 1.5327\n",
      "Epoch 85/100\n",
      "120000/120000 - 0s - loss: 3.3428 - val_loss: 1.5244\n",
      "Epoch 86/100\n",
      "120000/120000 - 0s - loss: 3.3844 - val_loss: 1.5326\n",
      "Epoch 87/100\n",
      "120000/120000 - 0s - loss: 3.3242 - val_loss: 1.5182\n",
      "Epoch 88/100\n",
      "120000/120000 - 0s - loss: 3.3172 - val_loss: 1.5239\n",
      "Epoch 89/100\n",
      "120000/120000 - 0s - loss: 3.3253 - val_loss: 1.5313\n",
      "Epoch 90/100\n",
      "120000/120000 - 0s - loss: 3.3923 - val_loss: 1.5282\n",
      "Epoch 91/100\n",
      "120000/120000 - 0s - loss: 3.3469 - val_loss: 1.5115\n",
      "Epoch 92/100\n",
      "120000/120000 - 0s - loss: 3.2895 - val_loss: 1.5338\n",
      "Epoch 93/100\n",
      "120000/120000 - 0s - loss: 3.3138 - val_loss: 1.5292\n",
      "Epoch 94/100\n",
      "120000/120000 - 0s - loss: 3.3399 - val_loss: 1.5220\n",
      "Epoch 95/100\n",
      "120000/120000 - 0s - loss: 3.3797 - val_loss: 1.5265\n",
      "Epoch 96/100\n",
      "120000/120000 - 0s - loss: 3.3536 - val_loss: 1.5130\n",
      "Epoch 97/100\n",
      "120000/120000 - 0s - loss: 3.3134 - val_loss: 1.5385\n",
      "Epoch 98/100\n",
      "120000/120000 - 0s - loss: 3.2797 - val_loss: 1.5270\n",
      "Epoch 99/100\n",
      "120000/120000 - 0s - loss: 3.2325 - val_loss: 1.5317\n",
      "Epoch 100/100\n",
      "120000/120000 - 0s - loss: 3.3343 - val_loss: 1.5331\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "          epochs=epochs, \n",
    "          batch_size=5000, \n",
    "          verbose=2, \n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 [1.51218904 1.59188272 1.57587394 0.81430325 0.81265348 0.80331397]\n"
     ]
    }
   ],
   "source": [
    "# fig, ax = plt.subplots(figsize=(12,8))\n",
    "# ax.set_title('Loss')\n",
    "# ax.plot(np.sqrt(history.history['loss']), label='train')\n",
    "# ax.plot(np.sqrt(history.history['val_loss']), label='test')\n",
    "# ax.legend();\n",
    "y_pred = model.predict(X_test)\n",
    "error_1000 = np.sqrt(mean_squared_error(y_test, y_pred, multioutput='raw_values'))\n",
    "print(steps, error_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-12.25550051, -27.8060288 ,   5.85832625,  -0.39903096,\n",
       "         -0.98290801,   0.23287413]),\n",
       " array([-11.78412   , -25.626331  ,   5.334454  ,  -0.45046738,\n",
       "         -1.009466  ,   0.23156069], dtype=float32))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0], y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48718450329195334 0.8255023558412633\n",
      "0.5702250433965922 0.8308453961088554\n",
      "1.5599819009454432 0.8100902337759422\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(error_10[:3]), np.mean(error_10[3:]))\n",
    "print(np.mean(error_100[:3]), np.mean(error_100[3:]))\n",
    "print(np.mean(error_1000[:3]), np.mean(error_1000[3:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p36)",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
